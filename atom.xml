<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>水木今山的博客</title>
  
  <subtitle>Coding the World</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-03-25T13:34:14.931Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>水木今山</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Reactor模式整理</title>
    <link href="http://yoursite.com/2020/03/25/Ractor%E6%A8%A1%E5%BC%8F%E6%95%B4%E7%90%86/"/>
    <id>http://yoursite.com/2020/03/25/Ractor模式整理/</id>
    <published>2020-03-25T12:52:00.000Z</published>
    <updated>2020-03-25T13:34:14.931Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一些思考"><a href="#一些思考" class="headerlink" title="一些思考"></a>一些思考</h2><p>先看下传统IO编程模型：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ClassicServer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            ServerSocket serverSocket = <span class="keyword">new</span> ServerSocket(<span class="number">8899</span>);</span><br><span class="line">            <span class="keyword">while</span>(<span class="keyword">true</span>) &#123;</span><br><span class="line">                Socket socket = serverSocket.accept();</span><br><span class="line"><span class="comment">//                new Thread(new Handler(socket)).start();</span></span><br><span class="line">                <span class="keyword">new</span> Handler(socket).run();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span>(IOException ex)&#123;</span><br><span class="line">            ex.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Handler</span> <span class="keyword">implements</span> <span class="title">Runnable</span></span>&#123;   <span class="comment">// 每个Handler在单独的线程中执行</span></span><br><span class="line">        <span class="keyword">final</span> Socket socket;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="title">Handler</span><span class="params">(Socket socket)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.socket = socket;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">try</span>&#123;</span><br><span class="line">                <span class="keyword">byte</span>[] input = <span class="keyword">new</span> <span class="keyword">byte</span>[Integer.MAX_VALUE];</span><br><span class="line">                socket.getInputStream().read(input);    <span class="comment">// 从流读取</span></span><br><span class="line">                <span class="keyword">byte</span>[] output = process(input);         <span class="comment">// 业务处理</span></span><br><span class="line">                socket.getOutputStream().write(output); <span class="comment">// 写入到流</span></span><br><span class="line">            &#125; <span class="keyword">catch</span>(IOException ex)&#123;</span><br><span class="line">                ex.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">byte</span>[] process(<span class="keyword">byte</span>[] cmd)&#123; <span class="keyword">return</span> cmd; &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>在学习完NIO后，心中一直有个疑问：不使用多线程的传统IO编程模型要在一个死循环中不断的接受连接然后处理请求，而NIO的编程模型也是要依次遍历监听到的已就绪的IO事件，同样也需要在某个循环中挨个处理，那么NIO相比于传统IO在处理时有什么本质区别吗？</p><p>实际上，如果不使用多线程，那么传统IO编程模型每次在调用完<code>accept()</code>后都要同步的去调用<code>socket.getInputStream().read(input);</code>阻塞地从流中读取数据。此时的问题在于，如果客户端在与服务器连接后迟迟不发送请求，那么线程就会一直阻塞在这里，这时候如果有别的客户端发送任何请求过来都没办法及时处理。当然，这个问题可以通过多线程来解决，也就是将上述<code>Handler.run()</code>放在单独的新线程中执行，但是线程的创建和销毁以及切换开销都是非常大的，所以在高并发的场景下性能将急剧下降，这也是NIO的出现所解决的问题之一。</p><p>通过使用NIO，<code>accept()</code>后，并不需要阻塞的去读取客户端发送过来的数据，而是将读事件注册到<code>Selector</code>上，等之后读事件就绪时再进行相应的处理即可（这可能发生在很多次的<code>select()</code>方法执行之后了）。因此，NIO使用一个线程就能达到传统IO要使用多个线程才能实现的目的。然而，这里有一点容易被忽视：这种单线程使用NIO的方式只能同步的依次去处理每一个事件，也就是说，在并发量比较低的场景下，使用多线程的传统IO编程模型可能会有更好的性能，因为它利用了多核的优势，这也是在Doug Lea的那篇文章中将Reactor模式不断演进的动力之一。</p><h2 id="优质资料"><a href="#优质资料" class="headerlink" title="优质资料"></a>优质资料</h2><ul><li><a href="http://www.dre.vanderbilt.edu/~schmidt/PDF/reactor-siemens.pdf" target="_blank" rel="noopener">Reactor An Object Behavioral Pattern for Demultiplexing and Dispatching Handles for Synchronous Events</a></li><li><a href="http://gee.cs.oswego.edu/dl/cpjslides/nio.pdf" target="_blank" rel="noopener">Scalable IO in Java</a></li><li><a href="http://www.blogjava.net/dlevin/archive/2015/09/02/427045.html" target="_blank" rel="noopener">Reactor模式详解</a></li><li><a href="https://www.s0nnet.com/archives/deep-understanding-of-reactor-design-patterns" target="_blank" rel="noopener">深入理解Reactor模式</a></li><li><a href="https://www.cnblogs.com/doit8791/p/7461479.html" target="_blank" rel="noopener">高性能IO之Reactor模式</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;一些思考&quot;&gt;&lt;a href=&quot;#一些思考&quot; class=&quot;headerlink&quot; title=&quot;一些思考&quot;&gt;&lt;/a&gt;一些思考&lt;/h2&gt;&lt;p&gt;先看下传统IO编程模型：&lt;br&gt;&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td 
      
    
    </summary>
    
    
      <category term="Netty" scheme="http://yoursite.com/tags/Netty/"/>
    
      <category term="Reactor" scheme="http://yoursite.com/tags/Reactor/"/>
    
  </entry>
  
  <entry>
    <title>浅析NIO与零拷贝</title>
    <link href="http://yoursite.com/2020/03/15/%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90NIO%E4%B8%8E%E9%9B%B6%E6%8B%B7%E8%B4%9D/"/>
    <id>http://yoursite.com/2020/03/15/深入分析NIO与零拷贝/</id>
    <published>2020-03-15T12:39:00.000Z</published>
    <updated>2022-03-02T07:54:27.036Z</updated>
    
    <content type="html"><![CDATA[<h2 id="传统IO拷贝"><a href="#传统IO拷贝" class="headerlink" title="传统IO拷贝"></a>传统IO拷贝</h2><p>传统IO的数据拷贝流程如下图：</p><p><img src="http://img.hecenjie.cn/zerocopy1.png" alt></p><ol><li>数据需要从磁盘拷贝到内核空间，再从内核空间拷到用户空间（JVM）。</li><li>程序可能进行数据修改等操作。</li><li>再将数据拷贝到内核空间，内核空间再拷贝到网卡内存，通过网络发送出去（或拷贝到磁盘）。</li></ol><p>即数据的读写（这里用户空间发到网络也算作写），都至少需要两次拷贝。</p><p>当然磁盘到内核空间属于DMA拷贝（DMA即直接内存存取，原理是外部设备不通过CPU而直接与系统内存交换数据）。而内核空间到用户空间则需要CPU的参与进行拷贝，既然需要CPU参与，也就涉及到了内核态和用户态的相互切换，如下图：</p><p><img src="http://img.hecenjie.cn/zerocopy2.png" alt></p><h2 id="NIO零拷贝"><a href="#NIO零拷贝" class="headerlink" title="NIO零拷贝"></a>NIO零拷贝</h2><p><code>sendfile</code>和<code>mmap</code>本质上都是基于零拷贝技术实现的，在Java NIO中，其分别通过<code>FileChannel</code>的<code>transferTo()</code>和<code>map()</code>提供支持。</p><h3 id="sendfile"><a href="#sendfile" class="headerlink" title="sendfile"></a>sendfile</h3><p><code>sendfile</code>的数据拷贝如下图：</p><p><img src="http://img.hecenjie.cn/zerocopy3.png" alt></p><p>内核态与用户态切换如下图：</p><p><img src="http://img.hecenjie.cn/zerocopy5.png" alt></p><p>改进的地方：</p><ol><li>我们已经将上下文切换次数从4次减少到了2次。</li><li>将数据拷贝次数从4次减少到了3次（其中只有1次涉及了CPU，另外2次是DMA直接存取）。</li></ol><p>但这还没有达到我们零拷贝的目标。如果底层NIC（网络接口卡）支持gather操作，我们能进一步减少内核中的数据拷贝。在Linux 2.4以及更高版本的内核中，Socket缓冲区描述符已被修改用来适应这个需求。简单来说，传输的数据不需要连续的内存空间，整个过程中并没有实际内容数据从内核缓冲区拷贝到Socket缓冲区，取而代之的是将包含数据的位置以及长度的描述符附加到Socket缓冲区，之后直接从内核缓冲区进行收集然后传输即可。这种方式不但减少多次的上下文切换，同时消除了需要CPU参与的重复的数据拷贝。用户这边的使用方式不变，而内部已经有了质的改变：</p><p><img src="http://img.hecenjie.cn/zerocopy4.png" alt></p><h3 id="mmap"><a href="#mmap" class="headerlink" title="mmap"></a>mmap</h3><p>以上都建立在整个过程不需要进行额外的数据文件操作的情况下，如果既需要这样的速度，也需要进行数据操作就可以使用<code>mmap</code>（内存映射文件）。<code>mmap</code>将文件的内容从内核缓冲区映射到用户的进程中，这样就不需要拷贝了，但是<code>mmap</code>有个缺点是如果其他进程在向这个文件write，那么会被认为是一个错误的存储访问。除此之外，<code>mmap</code>最后向网卡传输时必须将数据从内核缓冲区拷贝到Socket缓冲区。</p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>传统IO拷贝：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Server</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OldIOServer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        ServerSocket serverSocket = <span class="keyword">new</span> ServerSocket();</span><br><span class="line">        serverSocket.bind(<span class="keyword">new</span> InetSocketAddress(<span class="number">8899</span>));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            Socket socket = serverSocket.accept();</span><br><span class="line">            DataInputStream dataInputStream = <span class="keyword">new</span> DataInputStream(socket.getInputStream());</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="keyword">byte</span>[] byteArray = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">4096</span>];</span><br><span class="line">                <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">                    <span class="keyword">int</span> readCount = dataInputStream.read(byteArray, <span class="number">0</span>, byteArray.length);</span><br><span class="line">                    <span class="keyword">if</span> (-<span class="number">1</span> == readCount) &#123;</span><br><span class="line">                        <span class="keyword">break</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Client</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OldIOClient</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        Socket socket = <span class="keyword">new</span> Socket(<span class="string">"localhost"</span>, <span class="number">8899</span>);</span><br><span class="line">        String fileName = <span class="string">"/Users/hecenjie/Downloads/joker.mp4"</span>;</span><br><span class="line">        InputStream inputStream = <span class="keyword">new</span> FileInputStream(fileName);</span><br><span class="line">        DataOutputStream dataOutputStream = <span class="keyword">new</span> DataOutputStream(socket.getOutputStream());</span><br><span class="line">        <span class="keyword">byte</span>[] buffer = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">4096</span>];</span><br><span class="line">        <span class="keyword">long</span> readCount;</span><br><span class="line">        <span class="keyword">long</span> total = <span class="number">0L</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">long</span> startTime = System.currentTimeMillis();</span><br><span class="line">        <span class="keyword">while</span>((readCount = inputStream.read(buffer) )&gt;= <span class="number">0</span>) &#123;</span><br><span class="line">            total += readCount;</span><br><span class="line">            dataOutputStream.write(buffer);</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(<span class="string">"[old] 发送总字节数: "</span> + total + <span class="string">" , 耗时: "</span> + (System.currentTimeMillis() - startTime) + <span class="string">"毫秒"</span>);</span><br><span class="line">        dataOutputStream.close();</span><br><span class="line">        socket.close();</span><br><span class="line">        inputStream.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>NIO零拷贝：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Server</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">NewIOServer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        InetSocketAddress address = <span class="keyword">new</span> InetSocketAddress(<span class="number">8899</span>);</span><br><span class="line">        ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();</span><br><span class="line">        ServerSocket serverSocket = serverSocketChannel.socket();</span><br><span class="line">        serverSocket.setReuseAddress(<span class="keyword">true</span>);</span><br><span class="line">        serverSocket.bind(address);</span><br><span class="line"></span><br><span class="line">        ByteBuffer byteBuffer = ByteBuffer.allocate(<span class="number">4096</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            SocketChannel channel = serverSocketChannel.accept();</span><br><span class="line">            channel.configureBlocking(<span class="keyword">true</span>);</span><br><span class="line">            <span class="keyword">int</span> readCount = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">while</span>(-<span class="number">1</span> != readCount) &#123;</span><br><span class="line">                <span class="keyword">try</span>&#123;</span><br><span class="line">                    readCount = channel.read(byteBuffer);</span><br><span class="line">                    byteBuffer.rewind();</span><br><span class="line">                &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Client</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">NewIOClient</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        SocketChannel socketChannel = SocketChannel.open();</span><br><span class="line">        String fileName = <span class="string">"/Users/hecenjie/Downloads/joker.mp4"</span>;</span><br><span class="line">        FileChannel fileChannel = <span class="keyword">new</span> FileInputStream(fileName).getChannel();</span><br><span class="line">        socketChannel.connect(<span class="keyword">new</span> InetSocketAddress(<span class="string">"localhost"</span>, <span class="number">8899</span>));</span><br><span class="line">        socketChannel.configureBlocking(<span class="keyword">true</span>);</span><br><span class="line">        <span class="comment">// begin</span></span><br><span class="line">        sendfile(fileChannel, socketChannel);</span><br><span class="line">        mmap(fileChannel, socketChannel);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">sendfile</span><span class="params">(FileChannel fileChannel, SocketChannel socketChannel)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">long</span> position = <span class="number">0L</span>;</span><br><span class="line">        <span class="keyword">long</span> startTime = System.currentTimeMillis();</span><br><span class="line">        <span class="keyword">while</span>(position &lt; fileChannel.size()) &#123;</span><br><span class="line">            <span class="comment">// 如果socketChannel是非阻塞的，可能就读取不到指定数量的字节</span></span><br><span class="line">            position += fileChannel.transferTo(position, Math.min(<span class="number">2147483647L</span>, fileChannel.size()-position), socketChannel);</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(<span class="string">"[sendfile] 发送总字节数: "</span> + position + <span class="string">" , 耗时: "</span> + (System.currentTimeMillis() - startTime) + <span class="string">"毫秒"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">mmap</span><span class="params">(FileChannel fileChannel, SocketChannel socketChannel)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        MappedByteBuffer mbb;</span><br><span class="line">        <span class="keyword">long</span> position = <span class="number">0L</span>;    <span class="comment">// 同时也充当position的作用</span></span><br><span class="line">        <span class="keyword">long</span> startTime = System.currentTimeMillis();</span><br><span class="line">        <span class="keyword">while</span>(position &lt; fileChannel.size())&#123;</span><br><span class="line">            mbb = fileChannel.map(FileChannel.MapMode.READ_ONLY, position, Math.min(fileChannel.size()-position, Integer.MAX_VALUE));</span><br><span class="line">            position += socketChannel.write(mbb);</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(<span class="string">"[mmap] 发送总字节数: "</span> + position + <span class="string">" , 耗时: "</span> + (System.currentTimeMillis() - startTime) + <span class="string">"毫秒"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>实验结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[old] 发送总字节数: 2300047434 , 耗时: 2572毫秒</span><br><span class="line">[sendfile] 发送总字节数: 2300047434 , 耗时: 474毫秒</span><br><span class="line">[mmap] 发送总字节数: 2300047434 , 耗时: 1271毫秒</span><br></pre></td></tr></table></figure></p><p>这里有几点需要特别注意的地方。首先，<code>transferTo()</code>是有处理长度限制的，也就是<code>2147483647L</code>个字节（2GB - 1）。所以如果处理超过2GB的文件就要循环执行<code>transferTo()</code>方法，直至处理长度和文件长度一样为止。其次，如果将<code>SocketChannel</code>设置成非阻塞的，可能就读取不到指定数量的字节，因此如果使用之前没有循环的方式，会发现就算是小于2GB的文件也传输不完，而使用循环的方式则天然的解决了此问题。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://juejin.im/post/5c1c532551882579520b1f47" target="_blank" rel="noopener">浅谈NIO与零拷贝</a></li><li><a href="http://sound2gd.wang/2018/07/24/Java-NIO%E5%88%86%E6%9E%90-11-%E9%9B%B6%E6%8B%B7%E8%B4%9D%E6%8A%80%E6%9C%AF/" target="_blank" rel="noopener">Java NIO分析(11): 零拷贝技术以及NIO的支持</a></li><li><a href="https://blog.csdn.net/weixin_37782390/article/details/103833306" target="_blank" rel="noopener">什么是零拷贝？mmap与sendFile的区别是什么？</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;传统IO拷贝&quot;&gt;&lt;a href=&quot;#传统IO拷贝&quot; class=&quot;headerlink&quot; title=&quot;传统IO拷贝&quot;&gt;&lt;/a&gt;传统IO拷贝&lt;/h2&gt;&lt;p&gt;传统IO的数据拷贝流程如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://img.hecenjie.c
      
    
    </summary>
    
    
      <category term="NIO" scheme="http://yoursite.com/tags/NIO/"/>
    
      <category term="零拷贝" scheme="http://yoursite.com/tags/%E9%9B%B6%E6%8B%B7%E8%B4%9D/"/>
    
  </entry>
  
  <entry>
    <title>我对Raft的一些理解</title>
    <link href="http://yoursite.com/2020/02/09/%E5%AF%B9Raft%E7%9A%84%E4%B8%80%E4%BA%9B%E7%90%86%E8%A7%A3/"/>
    <id>http://yoursite.com/2020/02/09/对Raft的一些理解/</id>
    <published>2020-02-09T14:14:00.000Z</published>
    <updated>2022-03-02T07:54:47.764Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>这段时间通读了一遍Raft论文，虽说其相较Paxos算法而言浅显易懂了许多，但是倘若真正深入理解其中的一些细节，依然还是有许多比较复杂的地方。因此，本文将着重记录自己对于论文中的一些难点的思考过程，而对于Raft的一些基础概念将不会再花篇幅介绍。本文结论大多比较主观，如有疑问欢迎指出。</p><h2 id="强一致or最终一致性"><a href="#强一致or最终一致性" class="headerlink" title="强一致or最终一致性"></a>强一致or最终一致性</h2><p>在第一次读完Raft论文后，产生的第一个思考就是Raft到底是属于强一致性还是最终一致性。因为Raft并不需要将日志复制到每个节点上才返回，而只要大多数节点都收到即可，因此容易误以为Raft属于一个最终一致性的协议。但实际上，根据强/弱/最终一致性的简单定义：</p><blockquote><p>强一致性集群中，对任何一个节点发起请求都会得到相同的回复，但将产生相对高的延迟。而弱一致性具有更低的响应延迟，但可能会回复过期的数据，最终一致性即是经过一段时间后终会到达一致的弱一致性。</p></blockquote><p>Raft是属于强一致性的，客户端不会读到过期的结果，且并不要求将每个写请求复制到集群中的每个节点上。这是由于Raft的领导人完全特性保证了领导人一定拥有所有已经被提交的日志条目，并且在论文中还提到：</p><blockquote><p>Raft handles this by having the leader exchange heartbeat messages with a majority of the cluster before responding to read-only requests.</p></blockquote><p>即一个Leader在响应只读请求之前，需要先和集群中的大多数节点交换一次心跳，来及时发现自己是否已经被废黜了。</p><h2 id="提交之前任期内的日志条目"><a href="#提交之前任期内的日志条目" class="headerlink" title="提交之前任期内的日志条目"></a>提交之前任期内的日志条目</h2><p>刚开始看到论文中5.4.2节时不太清楚作者究竟想表达什么，后来反复阅读了原文才知晓其中的含义。</p><p><img src="http://img.hecenjie.cn/截屏2020-02-09下午8.33.37.png" alt></p><p>这一段表达的意思其实就是Leader只会提交自己任期内副本超过半数的日志条目，就算看到了（甚至是复制了）之前任期的日志条目副本超过半数了，依然也不会主动去提交，因为它是有可能被覆盖的（如图8中d的情况），一旦提交并返回客户端成功就出错了（也就是非线性一致性，即之前响应客户端commit成功的请求被回退了）。所以把提交的时机交给当前任期的日志被成功复制后，提交当前任期的日志时会间接提交之前任期的日志（因为提交就是移动一下commitIndex），这样才能保障提供线性一致性。</p><p>在某篇博客中对此有个更通俗易懂的解释：</p><blockquote><p>提交的限制 5.4.2 这个图配上说明非常迷惑，其实他就是说如果leader的current term是4，你不能直接去提交自己的最大日志是term=2的那条日志，就算这个日志leader知道已经被所有机器接受也不能提交这个日志。如果你提交该日志就可能被s5覆盖，破坏raft的安全，当然不提交也会被s5覆盖，但raft只保证被提交日志的安全性;比current term小的日志term，Leader就不会去统计该日志是否被大多数节点接受。只有当有个新日志并且其必须term=4被大多数节点接受，然后可以直接提交这个term=4的新日志;这样可以导致之前的term=2的日志也被默认提交了。</p></blockquote><p>除此之外，为了防止当前任期的写请求迟迟不来，导致Leader没法提供对这部分不知道有没有提交的日志的读服务，所以Raft通过Leader在任期开始的时候提交一个空白的没有任何操作的日志条目（NO-OP LogEntry）到日志中去，以此保障快速进入正常可读状态。</p><blockquote><p>First, a leader must have the latest information on<br>which entries are committed. The Leader Completeness<br>Property guarantees that a leader has all committed entries, but at the start of its term, it may not know which<br>those are. To find out, it needs to commit an entry from<br>its term. Raft handles this by having each leader commit a blank no-op entry into the log at the start of its<br>term. </p></blockquote><h2 id="集群成员变更"><a href="#集群成员变更" class="headerlink" title="集群成员变更"></a>集群成员变更</h2><p>集群成员变更是整篇论文里最晦涩难懂的，其核心问题就是在于各个节点见到新配置的时间点是不同的，从而导致两个节点各自使用新老配置完成选举，从而产生两个Leader：<br><img src="http://img.hecenjie.cn/截屏2020-02-09下午9.15.27.png" alt></p><p>在上图的箭头指向的时间点，Server1可以通过Server1和Server2的投票完成选举，而Server5可以通过Server3、Server4、Server5的投票完成选举。因此，Raft使用joint consensus的方式避免多个节点同时单方面使用新老配置作出决策。</p><p>joint consensus主要分两阶段修改配置，并且在更新过程中，完全不影响集群的可用性：</p><ol><li>当Leader收到新配置C_new的时候，他首先是把它与老配置做并集，生成一个C_old_new配置。Leader会将C_old_new日志发到所有成员，直到大多数已经成功收到这个配置的日志。</li><li>如果大多数机器都收到C_old_new日志，Leader便将C_old_new提交，然后Leader再把C_new发到集群中。</li></ol><p>这里有几点需要额外注意：</p><ul><li>一旦一个服务器将新的配置日志条目增加到它的日志中，他就会用这个配置来做出未来所有的决定，而无论是否已经提交。</li><li>C_old_new达成一致需要分别在两种配置上获得大多数的支持。</li><li>一定要等到C_old_new被提交后再创建一条关于C_new配置的日志条目并复制给集群才是安全的。因为如果没有提交，就算被复制给了大多数，也依然有可能被覆盖掉（论文中介绍领导人完整性时有提到这种情况），这时候就又回到了C_old和C_new共同决定的局面。</li></ul><p>论文在这部分还指出了三个问题（由于篇幅过长，就不粘贴了）。第一个问题意思是在新机器加入集群时，在配置变更流程开始前，需要先完成数据同步；第二个问题相对来说比较复杂，意思是当C_old_new日志提交后，根据领导人完整性特性，仅具有C_old日志的机器已经无法当选Leader，这时候具有C_old_new或C_new日志的机器才可以当选Leader（这取决于赢得选举的候选人是否已经接收到了C-new日志），也就是说这时候依然可能依赖C_old的配置。而当C_new提交后，就只有具有C_new日志的机器可以当选Leader，此时就不再需要C_old配置上的机器了，不在C_new配置上的Leader这时候也可以过渡了。</p><p>当然，如果最开始的C_old_new日志都提交失败了，被选出来的新领导人可能是使用C-old配置也可能是C-old,new配置，和上面的思路是一样的。</p><blockquote><p>If the leader crashes,<br>a new leader may be chosen under either Cold or Cold,new,<br>depending on whether the winning candidate has received<br>Cold,new.</p></blockquote><p>实际上，现在开源的Raft实现上基本都不采用这种模式，而是更为简单的Single Cluster MemberShip Change（单节点变更算法）。我们可以注意到上面之所以会产生两个Leader的本质原因其实在于新旧配置的大多数（Majority）不存在交集，因此，倘若可以让新旧配置的大多数产生交集，这个交集就可以充当仲裁者的角色，单节点变更算法就是基于这个思想，每次只允许出现一个节点变更(增加或减小)，那么新配置和旧配置的大多数总会相交。</p><p><img src="http://img.hecenjie.cn/截屏2020-02-09下午10.05.41.png" alt></p><p>而关于这个算法依然还有许多注意点，比如说如下这种情况：</p><p><img src="http://img.hecenjie.cn/截v2-664ebcdb05d9e3c93259922d20975156_r.jpg" alt></p><p>对于这个问题，braft提出“Leader启动的时候就发送NO_OP请求，将上一个AddPeer/RemovePeer变为committed, 并使未复制到当前Leader的AddPeer/RemovePeer失败。直等到NO_OP请求committed之后, 可以安全地创建一个新的configuration并开始复制它。”</p><blockquote><p>Leader启动的时候先发送一个AddPeer或者是NOP请求是非常重要的：如果集群数量为偶数，并且上一个Leader最后在进行节点变更的时候宕机没有commit到多数；新的Leader如果启动就改变其节点集合，按照新节点集可能判断为Committed，但是之前老的Leader启动之后按照新的节点集合形成另外一个多数集合将之前未Commit的节点变更日志变为Committed，这样就产生了脑裂，可能会造成数据丢失。新的Leader启动之后必须Commit一条数据非节点变更日志后才能够进行发起节点变更，这条Committed的非节点变更日志可以保证至少跟之前UnCommitted的日志有一个节点交集，这样就可以保证UnCommitted的节点变更日志不会再变为Committed。详细讨论参见：<a href="https://groups.google.com/forum/#!topic/RAFT-dev/t4xj6dJTP6E" target="_blank" rel="noopener">https://groups.google.com/forum/#!topic/RAFT-dev/t4xj6dJTP6E</a></p></blockquote><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="file:///Users/hecenjie/Library/Mobile%20Documents/com~apple~CloudDocs/%E8%AE%BA%E6%96%87/Raft.pdf" target="_blank" rel="noopener">In Search of an Understandable Consensus Algorithm(Extended Version)</a></li><li><a href="https://lentil1016.cn/consistencies-and-raft/" target="_blank" rel="noopener">强一致性与最终一致性与raft</a></li><li><a href="https://zhuanlan.zhihu.com/p/29678067" target="_blank" rel="noopener">Raft 一致性协议</a></li><li><a href="https://juejin.im/post/5aed9a7551882506a36c659e" target="_blank" rel="noopener">别再怀疑自己的智商了，Raft协议本来就不好理解</a></li><li><a href="https://youjiali1995.github.io/raft/etcd-raft-cluster-membership-change/" target="_blank" rel="noopener">Raft 笔记(六) – Cluster membership change</a></li><li><a href="https://izualzhy.cn/notes-on-raft" target="_blank" rel="noopener">菜鸟读Raft论文 </a></li><li><a href="https://www.jianshu.com/p/80fb90fff5ba" target="_blank" rel="noopener">Raft协议细节理解</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;这段时间通读了一遍Raft论文，虽说其相较Paxos算法而言浅显易懂了许多，但是倘若真正深入理解其中的一些细节，依然还是有许多比较复杂的地方
      
    
    </summary>
    
    
      <category term="分布式" scheme="http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>《Dynamo》论文笔记</title>
    <link href="http://yoursite.com/2020/02/07/%E3%80%8ADynamo%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    <id>http://yoursite.com/2020/02/07/《Dynamo》论文笔记/</id>
    <published>2020-02-07T10:12:00.000Z</published>
    <updated>2022-03-02T07:55:04.766Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Dynamo是Amazon实现的一个高可用键值存储系统。它主要是针对以下场景而设计的：</p><ul><li>通过唯一的key对数据进行读写，且存储的内容一般较小。</li><li>不需要复杂的事务操作。</li><li>对延迟的要求十分严格。</li><li>假设环境是安全的，不需要考虑认证和鉴权等问题。</li></ul><p>除此之外，Dynamo还有以下一些设计原则：</p><ul><li>永远可写。</li><li>高可扩展性。</li><li>对称性、去中心化、点对点。</li><li>异构性。</li></ul><h2 id="分片算法"><a href="#分片算法" class="headerlink" title="分片算法"></a>分片算法</h2><p>Dynamo使用基于一致性哈希的分片方案。初级的一致性哈希算法会导致数据倾斜问题，因此使用虚拟节点均衡了负载。但尽管如此，当一个节点加入或离开系统时，需要将一部分key range移交给别的节点，这时会扫描整个本地持久存储以过滤出所需的数据，并且Merkle tree也需要重新计算。</p><p>Dynamo最终使用的分片方案是将哈希环等分Q份，T个机器节点时，每个机器分得S个分片，其中Q=T*S。由于分片固定大小，可对应单个文件，因此容易加入或删除节点，且容易备份。</p><h2 id="系统接口"><a href="#系统接口" class="headerlink" title="系统接口"></a>系统接口</h2><p>Dynamo将数据复制到N台机器上（N是可配置的）。存储某个特定key的所有节点组成一个优先列表（为了容错，列表节点会大于N个），并且由于引入了虚拟节点，优先列表在选择节点的时候会跳过一些位置，以防止相同的物理节点。</p><p>Dynamo存储键值对象对接口非常简单，它提供两个操作：</p><ul><li><code>get()</code></li><li><code>put()</code></li></ul><p>任何存储节点都可以接受任何key的<code>get()</code>和<code>put()</code>操作请求。为了保证副本的一致性，Dynamo使用了一种类似仲裁系统（quorum systems）的一致性协议，这个协议有两个配置参数：</p><ul><li>R：允许执行一次读操作所需的最少投票者</li><li>W：允许执行一次写操作所需的最少投票者</li></ul><p>其中，<code>R + W &gt; N</code>（R或W至少有一个超过半数），只要<code>R + W &gt; N</code>便可以保证客户端一定能读到最新版本的数据，因为这意味着R和W中至少有一个节点存在于交集之中（鸽笼原理）。</p><p><code>put()</code>操作流程：当收到一个<code>put()</code>请求后，coordinator节点（必须是优先列表中的）会为新版本数据生成vector clock并将其保存到本地，然后将新版本数据发送给前N个健康节点，只要有至少W-1个节点返回成功，这次写操作就认为是成功了。</p><p><code>get()</code>操作流程：对于一次<code>get()</code>请求，coordinator节点会向前N个健康节点请求这个key对应的数据，等到R个响应之后，就将结果返回给客户端。如果coordinator收到了这个数据的多个版本，就会将没有因果关系的所有版本都响应给客户端。</p><p>为了提高系统的可用性和持久性，Dynamo的仲裁机制是宽松的，即读写操作只需在优先列表的前N个健康节点上执行，而不一定非要是前N个节点。换句话说，当遇到不健康的节点时，会沿着一致性哈希环的顺时针方向顺延，将数据保存到一个临时节点的本地的一个独立数据库中，并且不断扫描原节点是否可用，一旦可用了就将这个数据归还，并将其从本地数据库中删除，这个过程就是Dynamo的Hinted Handoff。</p><p>还需要注意的是，每个节点都可以作为读请求的coordinator，而写请求的coordinator必须由key的优先列表里面的节点才能充当，因为优先列表中的节点被赋予了额外的职责：创建一个新的版本戳。</p><h2 id="数据版本"><a href="#数据版本" class="headerlink" title="数据版本"></a>数据版本</h2><p>Dynamo只提供最终一致性，所有更新操作会异步地传递给所有的副本，因此同一个数据可能会存在多个版本。</p><p>Dynamo使用vector clock来跟踪同一个对象不同版本之间的因果性，自动解决具有因果性的版本冲突，并且将不具有因果性的版本冲突交给应用层自行合并。一个vector clock分量就是一个<code>(node, counter)</code>，通过列出数据在每个节点上的处理序列可以发现不同版本之间的因果关系，当某个vector clock的所有分量都小于另一个时，该vector clock便是另一个的因，可以被覆盖。</p><p><img src="http://img.hecenjie.cn/截屏2020-02-07下午3.59.23.png" alt></p><p>如上图所示，D1与D2是没有版本冲突的，D1是作为D2的因，因此可以用D2将D1数据直接给覆盖掉。但是D3和D4是并行分支的关系，系统没办法将其自动合并，所以这两个版本都会被保留并在读取时交给客户端，由客户端自己负责解决这个冲突，并将其写回。</p><h2 id="同步恢复"><a href="#同步恢复" class="headerlink" title="同步恢复"></a>同步恢复</h2><p>上面介绍的Hinted Handoff机制在节点临时出现故障时提高了系统的可用性，但如果临时节点在归还数据前也故障了，那么需要有一种机制让原节点能与其它健康节点保持一致。因此，Dynamo实现了一种逆熵（副本同步）协议来保证副本之间数据的一致性。</p><p>Dynamo使用了Merkle tree通过仅发送不同的部分来减少数据传输量：</p><ul><li>每一个分片维护一个Merkle Tree。</li><li>需要比较分片是否相同时，自根向下的比较两个Merkle Tree的对应节点，从而快速定位不同的部分。</li></ul><p>关于Merkle tree在这篇博客中有很好的介绍：<a href="http://tao.he.cn/2018/07/01/Merkle%E6%A0%91/" target="_blank" rel="noopener">Merkle 树</a>。</p><h2 id="成员信息及故障检测"><a href="#成员信息及故障检测" class="headerlink" title="成员信息及故障检测"></a>成员信息及故障检测</h2><ul><li>为了避免节点失效导致再平衡后又恢复，Dynamo加入或离开集群都需要手动通过命令完成；</li><li>当有用户请求时，coordinator会发现不可达的节点，并用其他节点代替之，之后开始周期性探测其恢复；</li><li>Dynamo集群中的每台机器都会维护当前集群的成员及节点不可达等信息，这些信息通过gossip协议广播到整个集群；</li><li>客户端可以通过任意一个节点获得并维护这种成员信息，从而精确的找到自己要访问的数据所在。</li></ul><h2 id="添加-移除存储节点"><a href="#添加-移除存储节点" class="headerlink" title="添加/移除存储节点"></a>添加/移除存储节点</h2><p>当一个新节点X加入到系统后，它会获得一些随机分散在哈希环上的token。对每个分配给X的key range，当前可能已经有一些节点在负责处理了。因此，将key range分配给X后，这些节点就不需要处理这些key对应的请求了，而要将keys转给X。</p><p>考虑一个简单的情况：X加入下图中A和B之间。这样，X就负责处理落到 (F, G], (G, A] 和 (A, X] 之间的key。结果，B、C和D节点就不需要负责相应range了。因此，在收到X的转移key请求之后，B、C和D会向X转移相应的key。当移除一个节点时，key重新分配的顺序和刚才相反。</p><p><img src="http://img.hecenjie.cn/截屏2020-02-07下午5.21.38.png" alt></p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://s3.amazonaws.com/AllThingsDistributed/sosp/amazon-dynamo-sosp2007.pdf" target="_blank" rel="noopener">Dynamo: Amazon’s Highly Available Key-value Store</a></li><li><a href="https://toutiao.io/posts/iniasj/preview" target="_blank" rel="noopener">Amazon Dynamo 论文学习笔记</a></li><li><a href="https://catkang.github.io/2016/05/27/dynamo.html" target="_blank" rel="noopener">Dynamo论文介绍</a></li><li><a href="https://zhuanlan.zhihu.com/p/27853552" target="_blank" rel="noopener">知乎专栏Dynamo</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;p&gt;Dynamo是Amazon实现的一个高可用键值存储系统。它主要是针对以下场景而设计的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通过唯一的key对数据进行
      
    
    </summary>
    
    
      <category term="分布式" scheme="http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>《Bigtable》论文笔记</title>
    <link href="http://yoursite.com/2020/02/04/%E3%80%8ABigtable%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    <id>http://yoursite.com/2020/02/04/《Bigtable》论文笔记/</id>
    <published>2020-02-04T03:39:00.000Z</published>
    <updated>2022-03-02T07:55:34.991Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在阅读并总结了《Google File System》和《MapReduce》两篇论文后，终于迎来了谷歌技术“三宝”最后一项Bigtable。令人头疼的是，在通读了整篇论文后，感觉Bigtable相较于前面两篇晦涩难懂太多，尤其是文中提出的各种术语又没有解释的特别清楚，所以很多部分只能靠推测的方式一步步摸索。后来在B站上看到一个讲解视频十分通俗易懂：<a href="https://www.bilibili.com/video/av43773058?from=search&amp;seid=7451857285946803647" target="_blank" rel="noopener">深入浅出Bigtable</a>，因此本文将结合论文以及视频中的内容进行总结，如果有理解错误的地方，欢迎指出。</p><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Bigtable是一个分布式的结构化数据存储系统，它被设计用来处理海量数据：通常是分布在数千台普通服务器上的PB级的数据。</p><h2 id="数据模型"><a href="#数据模型" class="headerlink" title="数据模型"></a>数据模型</h2><p>实际上，Bigtable根本不是table，它的物理存储形式其实是一个排序Map。Map的key是行关键字、列关键字以及时间戳的复合结构，而value则是一个简单的string：<code>(row:string,column:string,time:int64)→string</code>。</p><p>Bigtable通过行关键字的字典顺序来组织数据，表中的每个行都可以动态分区，每个分区叫做一个Tablet，Tablet是数据分布和负载均衡调整的最小单位。</p><p>若干个列可以组成列族，因此列关键字的命名形式是：<code>列族:限定词</code>。用户在使用前必须首先声明有哪些列族，声明后即可在该列族中创建任意列。</p><p>每一个数据项都可以包含同一份数据的不同版本，不同版本的数据通过时间戳来索引。并且为了减轻多个版本数据的管理负担，Bigtable可以通过设置参数来对废弃版本的数据自动进行垃圾收集。</p><h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p>Bigtable包括三个主要的组件：链接到客户程序中的库、一个Master服务器和多个Tablet服务器。Master服务器主要负责以下工作：为Tablet服务器分配Tablets、检测新加入的或者过期失效的Tablet服务器、对Tablet服务器进行负载均衡、对保存在GFS上的文件进行垃圾收集、处理对模式的相关修改操作如建立表和列族。</p><p>初始状态下，一个表只有一个Tablet，随着表中数据的增长，它被自动分割成多个Tablet，缺省情况下，每个Tablet的尺寸大约是100MB到200MB。</p><p><img src="http://img.hecenjie.cn/截屏2020-02-03下午10.34.29.png" alt></p><p>Bigtable使用GFS存储数据文件，并且是SSTable格式的。SSTable是一个持久化的、排序的、不可更改的Map结构（也就是一系列key-value对）：</p><p><img src="http://img.hecenjie.cn/截屏2020-02-03下午9.20.44.png" alt></p><p>当我们写数据的时候，首先是写在内存表中，而不是直接写入到SSTable中。写入到内存中速度更快，并且排序效率也更高：</p><p><img src="http://img.hecenjie.cn/截屏2020-02-03下午9.29.13.png" alt></p><p>当内存表大小达到阈值时，就将数据写入到磁盘，也就是生成一份新的SSTable：<br><img src="http://img.hecenjie.cn/截屏2020-02-03下午9.32.16.png" alt></p><p>但是在内存中的数据还没写入磁盘的过程中，有可能会发生丢失的情况，所以Bigtable通过预写日志解决了这个问题：<br><img src="http://img.hecenjie.cn/截屏2020-02-03下午9.34.57.png" alt></p><p>由于上面介绍的写策略，导致了虽然SSTable内部的数据是有序的，但是SSTable之间的数据是无序的，因此，当一个读操作请求到来时，系统首先检查memTable，如果没有找到这个key，就会逆序的一个一个检查SSTable文件，直到key被找到。由此可见，读操作会随着SSTable的个数增加变的越来越慢，因为每一个SSTable都要被检查。</p><p>Bigtable首先通过块索引勉强加快了整个读取的速度：<br><img src="http://img.hecenjie.cn/截屏2020-02-03下午9.43.24.png" alt></p><p>SSTable会把数据分成块进行存储，并在SSTable文件尾部保存块索引，块索引记录每个块结束的key及对应的offset。通过块索引，每次查找时先在内存中通过二分查找定位到SSTable中相应的数据块，然后进行一次磁盘访问，读取到块中的数据。</p><p>但即使有每个SSTable的索引，随着SSTable个数增多，读操作仍然很慢。即便有了合并操作，读操作仍然可能会访问大量的文件。因此，可以通过布隆过滤器将必然不存在我们想要查找的数据的SSTable给忽略：<br><img src="http://img.hecenjie.cn/截屏2020-02-03下午9.57.42.png" alt></p><p>其实上面的memTable加上SSTables就是我们常说的LSM（Log Structured Merge Trees）。B+树和log追加型文件是数据读写的两个极端，B+树读效率高而写效率差，log追加型文件写效率高而读效率差。因此要在排序和log追加型文件之间做个折中，于是就引入了LSM模型，通过名称可以看出LSM既有日志型的文件操作，提升写效率，又在每个SSTable中排序，保证了查询效率。</p><h2 id="细节"><a href="#细节" class="headerlink" title="细节"></a>细节</h2><h3 id="Tablet分配"><a href="#Tablet分配" class="headerlink" title="Tablet分配"></a>Tablet分配</h3><p>Bigtable使用Chubby跟踪记录Tablet服务器的状态。当一个Tablet服务器启动时，它在Chubby的一个指定目录下建立一个有唯一性名字的文件，并且获取该文件的独占锁。Master服务器实时监控着这个目录，因此Master服务器能够知道有新的Tablet服务器加入了。如果Tablet服务器丢失了Chubby上的独占锁，比如由于网络断开导致Tablet服务器和Chubby的会话丢失，它就停止对Tablet提供服务。只要文件还存在，Tablet服务器就会试图重新获得对该文件的独占锁；如果文件不存在了，那么Tablet服务器就不能再提供服务了，它会自行退出。</p><p>Master服务器通过轮询Tablet服务器文件锁的状态来检测何时Tablet服务器不再为它的Tablet提供服务，此时Master服务器就会尝试获取该Tablet服务器文件的独占锁，如果成功获取到了，就说明Chubby是正常运行的，而Tablet可能是宕机了或者网络故障，此时Master服务器就删除该Tablet服务器在Chubby上的服务器文件以确保它不再给Tablet提供服务，一旦Tablet服务器在Chubby上的服务器文件被删除了，Master服务器就把之前分配给它的所有Tablet放入未分配的Tablet集合中。</p><h3 id="压缩"><a href="#压缩" class="headerlink" title="压缩"></a>压缩</h3><ul><li>Minor Compaction：随着写请求的不断增多，memTable在内存中的空间不断增大，当memTable的大小达到一定阈值时，memTable被dump到GFS中成为不可变的SSTable。</li><li>Merging Compaction：随着memTable不断的变为SSTable，SSTable也不断增多，意味着读操作需要读取的SSTable也越来越多，为了限制SSTable的个数，Tablet Server会在后台将多个SSTable合并为一个。</li><li>Major Compaction：Major Compaction是一种特殊的Merging Compaction，只把所有的SSTable合并为一个SSTable，在非Major Compaction产生的SSTable中可能包含已经删除的数据，Major Compaction的过程会将这些数据真正的清除掉，避免这些数据浪费存储空间。</li></ul><h3 id="Locality-Group"><a href="#Locality-Group" class="headerlink" title="Locality Group"></a>Locality Group</h3><p>客户程序可以指定多个列族形成一个group，group单独存成一个sstable，将通常不会一起访问的列族分割成不同的group可以提高读取操作的效率，还可以将group设定为全部存储在内存中。</p><h3 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h3><p>Tablet服务器使用二级缓存策略：</p><ul><li>扫描缓存是第一级缓存，主要缓存Tablet服务器通过SSTable接口获取的Key-Value对，这对于经常要重复读取相同数据的应用程序来说非常有效。</li><li>Block缓存是二级缓存，缓存的是从GFS读取的SSTable的Block，这对于经常要读取刚刚读过的数据附近的数据的应用程序来说非常有效。</li></ul><h3 id="合并日志"><a href="#合并日志" class="headerlink" title="合并日志"></a>合并日志</h3><p>如果每个Tablet都生成自己的Commit日志，那么就会产生大量的文件，并且这些文件并行写入GFS会有大量的磁盘seek操作。因此，Bigtable实现为每个Tablet服务器一个Commit日志文件，这个日志文件中混合了对多个Tablet修改的日志记录。</p><p>这种公用日志的方式虽然提高了普通操作的性能，但是在恢复的时候就麻烦了。当一个Tablet服务器宕机时，它加载的Tablet将会被迁移到很多其它的Tablet服务器上，那些新的Tablet服务器要从原来的Tablet服务器的日志中提取修改操作进行恢复，每台新的Tablet服务器都要读取完整的日志文件然后只执行它需要恢复的Tablet的相关修改操作。对此的一个优化便是把日志分成64M的段在不同的Tablet服务器按照关键字进行并行排序，这样对同一个Tablet修改操作的日志记录就连续存放在了一起，此时只要一次磁盘seek操作再顺序读取即可。</p><h3 id="SSTable不变性"><a href="#SSTable不变性" class="headerlink" title="SSTable不变性"></a>SSTable不变性</h3><p>当从SSTable读取数据的时候，我们不必对文件系统访问操作进行同步。menTable是唯一一个能被读和写操作同时访问的可变数据结构，我们对memTable采用copy-on-write机制，从而允许读写操作并行执行。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://research.google/pubs/pub27898/" target="_blank" rel="noopener">Bigtable: A Distributed Storage System for Structured Data</a></li><li><a href="https://www.cnblogs.com/xybaby/p/9096748.html" target="_blank" rel="noopener">典型分布式系统分析：Bigtable</a></li><li><a href="https://www.bilibili.com/video/av43773058?from=search&amp;seid=7451857285946803647" target="_blank" rel="noopener">深入浅出Bigtable</a></li><li><a href="https://niceaz.com/2018/11/27/sstable/#sstable-%E8%B5%B7%E6%BA%90" target="_blank" rel="noopener">SSTable 原理</a></li><li><a href="https://zhuanlan.zhihu.com/p/24721857" target="_blank" rel="noopener">大数据那些事(10):李逵麻子，李鬼坑人–BigTable的数据模型</a></li><li><a href="https://mr-dai.github.io/bigtable/" target="_blank" rel="noopener">Bigtable 论文详述</a></li><li><a href="https://www.open-open.com/lib/view/open1424916275249.html" target="_blank" rel="noopener">Log Structured Merge Trees(LSM) 原理</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;在阅读并总结了《Google File System》和《MapReduce》两篇论文后，终于迎来了谷歌技术“三宝”最后一项Bigtable
      
    
    </summary>
    
    
      <category term="分布式" scheme="http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>《MapReduce》论文笔记</title>
    <link href="http://yoursite.com/2020/02/01/%E3%80%8AMapReduce%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    <id>http://yoursite.com/2020/02/01/《MapReduce》论文笔记/</id>
    <published>2020-02-01T13:36:00.000Z</published>
    <updated>2022-03-02T07:55:49.982Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>MapReduce是一个处理和生成超大数据集的编程模型和相关实现。基于MapReduce，用户只需通过Map和Reduce函数描述自己的计算问题，而不用关心计算在哪个机器上进行、相互之间如何通信、机器故障如何处理等复杂的问题。</p><h2 id="执行过程"><a href="#执行过程" class="headerlink" title="执行过程"></a>执行过程</h2><p><img src="http://img.hecenjie.cn/截屏2020-02-01下午7.21.23.png" alt></p><p>当用户调用MapReduce时，将发生下面的一系列动作：</p><ol><li>MapReduce库首先将输入文件分成M个数据片段，然后用户程序在一组机器集群上创建大量的程序副本。</li><li>程序副本中有一个Master程序和多个Worker程序，Master程序负责分配任务（M个Map任务和R个Reduce任务）。</li><li>被分配了Map任务的Worker程序读取相应的输入数据片段，从数据片段中解析出kv对，然后把kv对传给Map函数，Map函数产生中间kv对并缓存在内存中。</li><li>Map Reducer缓存中的kv对通过分区函数分成R个区域并定期写入本地磁盘。这些kv对在本地磁盘上的存储位置将被回传给Master，由Master负责把这些存储位置再传送给Reduce Worker。</li><li>Reduce Worker接受到Master发来的存储位置后，使用RPC从Map Worker所在主机的磁盘上读取这些数据。当Reducer Worker程序读取了所有中间数据后，通过对key进行排序使得具有相同key值的数据聚合在一起。</li><li>Reduce Worker程序遍历排序后的中间数据，对于每一个唯一的中间key值，Reduce Worker程序将这个key值和它相关的中间value值集合传递给用户自定义的Reduce函数。Reduce函数的输出被追加到所属分区的输出文件。</li><li>当所有的Map和Reduce任务都完成之后，Master唤醒用户程序。此时，用户程序里对MapReduce调用才返回。</li></ol><p>成功完成任务后，MapReduce的输出存放在R个输出文件中，而这些文件往往又被作为另外一个MapReduce的输入。</p><p>《设计数据密集型应用》书中对该过程的描述图也很形象：<br><img src="http://img.hecenjie.cn/截屏2020-02-01下午8.44.39.png" alt></p><h2 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h2><p>倒排索引的应用：<br><img src="http://img.hecenjie.cn/截屏2020-02-02上午10.47.38.png" alt="倒排索引"></p><p>在这个例子中，数据片段个数M和Map Worker数目相同，分区数R也和Reduce Worker数目相同，但在实际应用中，M和R往往比Worker数目要多。</p><h2 id="容错"><a href="#容错" class="headerlink" title="容错"></a>容错</h2><p>和大多数Unix工具一样，运行MapReduce作业通常不会修改输入，除了生成输出外没有任何副作用。当遇到崩溃和网络问题时，任务可以安全地重试，任何失败任务的输出都被丢弃。因此，容错的设计是十分方便的，MapReduce可以保证作业的最终输出与没有发生错误的情况相同，尽管这其中不得不重试各种任务。</p><p>每个工作中的任务把它的输出写到私有的临时文件中，每个Reduce任务生成一个这样的文件，而每个Map任务则生成R个这样的文件：</p><ul><li>当一个Map任务完成时，Map Worker发送一个包含R个临时文件名的完成消息给Master。如果Master从一个已经完成的Map任务再次接收到一个完成消息，Master将忽略这个消息，否则Master将这R个文件的名字记录在数据结构里。</li><li>当一个Reduce任务完成时，Reduce Worker以原子的方式把临时文件重命名为最终的输出文件。如果同一个Reduce任务在多台机器上执行，针对同一个最终的输出文件将有多个重命名操作执行，MapReduce依赖底层文件系统提供的重命名操作的原子性来保证最终的文件系统状态仅仅包含一个Reduce任务产生的数据。</li></ul><h2 id="本地化调度策略"><a href="#本地化调度策略" class="headerlink" title="本地化调度策略"></a>本地化调度策略</h2><p>网络带宽是一个相当匮乏的资源，所以将Worker调度到相应的输入数据所在的机器，从本地机器读取输入数据，从而减少网络带宽的消耗。这也是为什么我们所设的M值最好使得每个独立任务都处理不超过64M的输入数据，因为在GFS中每一个Chunk的大小就是64M，如果输入数据大于64M，就可能得从别的远程机器上读取其它Chunk中的数据，也就加大了网络开销。</p><h2 id="备用任务"><a href="#备用任务" class="headerlink" title="备用任务"></a>备用任务</h2><p>当一个MapReduce操作接近完成的时候，Master调度备用任务进程来执行剩下的、处理中的任务。无论是最初的执行进程还是备用任务进程完成来任务，我们都把这个任务标记为已完成。并且在上面容错机制已经提到，有两个Worker执行同一个任务是没有任何问题的。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/mapreduce-osdi04.pdf" target="_blank" rel="noopener">MapReduce: Simplified Data Processing on Large Clusters</a></li><li><a href="https://www.cnblogs.com/xybaby/p/8878054.html" target="_blank" rel="noopener">典型分布式系统分析：MapReduce</a></li><li><a href="https://www.bilibili.com/video/av43772900?from=search&amp;seid=9045060489116633572" target="_blank" rel="noopener">深入浅出讲解 MapReduce</a></li><li>Martin Kleppmann. 数据密集型应用系统设计. 中国电力出版社, 2018.</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;p&gt;MapReduce是一个处理和生成超大数据集的编程模型和相关实现。基于MapReduce，用户只需通过Map和Reduce函数描述自己的计算
      
    
    </summary>
    
    
      <category term="分布式" scheme="http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>《The Google File System》论文笔记</title>
    <link href="http://yoursite.com/2020/01/31/%E3%80%8AGoogle-File-System%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    <id>http://yoursite.com/2020/01/31/《Google-File-System》论文笔记/</id>
    <published>2020-01-31T09:57:00.000Z</published>
    <updated>2022-03-02T07:56:11.784Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Google File System（简称GFS）是一个面向大规模数据密集型应用的、可伸缩的分布式文件系统，其运行在廉价的普通硬件设备上，并且是基于Linux文件系统之上的。GFS主要是针对以下场景而设计的：</p><ul><li>组件经常失效。</li><li>存储大文件（数GB的文件非常普遍）。</li><li>写操作主要是顺序的追加写，而不是覆盖写。</li></ul><h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p>GFS系统包含三部分：客户端、单独的Master节点、多台Chunk服务器。所有这些机器通常都是普通的Linux机器，运行着用户级别的服务进程。</p><p><img src="http://img.hecenjie.cn/截屏2020-01-30下午4.39.01.png" alt="架构"></p><h3 id="Chunk"><a href="#Chunk" class="headerlink" title="Chunk"></a>Chunk</h3><p>GFS存储的文件被划分为固定大小的Chunk。每个Chunk在创建时会被分配一个Chunk句柄，即一个不变的、全局唯一的64位的ID。Chunk服务器把Chunk以Linux文件的形式保存在本地硬盘上，按照Chunk句柄和字节范围来读写Chunk数据。为了可靠性，每个Chunk被复制到多个Chunk服务器上，默认是3份（由复制因子指定）。</p><p>Chunk的大小为64M。选择这么大的Chunk尺寸有以下几个优点：</p><ul><li>减少了客户端和Master节点通讯的需求。</li><li>客户端能够对一个块进行多次操作，从而与Chunk服务器保持较长时间的TCP连接来减少网络负载。</li><li>减少了Master节点需要保存的元数据的数量。</li></ul><p>但大的Chunk尺寸也是有其缺陷的，即小文件包含较少的Chunk甚至只有一个Chunk，当有许多的客户端对同一个小文件进行多次访问时，存储这些Chunk的Chunk服务器就会变成热点。这个问题可以通过增大复制因子来解决。</p><p>这里还有一个值得思考的地方，即GFS对数据的冗余是以Chunk为基本单位而不是机器（或者说文件）。以机器为单位进行冗余的优点是简单方便，但是伸缩性不好，不能充分利用资源；而以Chunk为基本单位，虽然Master节点上需要存更多的元数据，但一个Chunk的信息也就64字节左右，而Chunk本身的粒度又有64M这么大，加之在Master中Chunk的位置信息是不持久化的，所以这并不会给Master带来太多的负担。</p><h3 id="Master"><a href="#Master" class="headerlink" title="Master"></a>Master</h3><p>Master主要存储三种类型的元数据：文件和Chunk的命名空间（GFS按层级目录管理文件）、文件到Chunk的映射关系<br>、Chunk的位置。所有的元数据均被保存在Master的内存中，前两种也会持久化保存，即通过记录操作日志，存储在Master的本地磁盘并且复制到远程机器。使用操作日志允许我们更简单可靠的更新Master状态，不会因为Master的宕机导致数据不一致。但是，Master不会持久化存储Chunk的位置，相反，Master会在启动时询问每个Chunk服务器以获取它们各自的Chunk信息，新Chunk服务器加入集群时也是如此。</p><p>操作日志对于GFS至关重要，它是元数据唯一的持久化存储记录。只有在把日志复制到多台远程机器，并且只有把相应的日志记录写入到本地以及远程机器的硬盘后才能响应客户端。Master节点在灾难恢复时通过重演操作日志把文件系统恢复到最近的状态，为了缩短Master启动的时间，我们必须使日志足够小，所以Master服务器在日志增长到一定量时对系统状态执行快照，而不需要从零开始回放日志，仅需要从本地磁盘装载最近的快照，并回放快照之后发生的有限数量的日志。</p><p>当然，在Master节点上持久化Chunk位置信息也不是不行，但由于只有Chunk服务器才能最终确定一个Chunk是否在它的硬盘上，所以定期轮询的方式更为简便和可靠，否则需要考虑Chunk服务器和Master服务器的数据同步问题，其实没这个必要在Master节点上大费周章的维护一个一致性视图。</p><p>Master也负责管理一些影响整个系统的活动，比如Chunk租赁管理、孤儿Chunk的垃圾回收，以及Chunk服务器之间的Chunk迁移。Master与Chunk服务器保持常规的心跳，以确定Chunk服务器的状态。</p><h3 id="Client"><a href="#Client" class="headerlink" title="Client"></a>Client</h3><p>GFS客户端代码以库的形式被链接到客户程序里。客户端只在获取元数据时与Master交互（客户端会缓存元数据），真实的数据操作会直接发至Chunk服务器。客户端和Chunk服务器都不会缓存文件数据。</p><h2 id="读取流程"><a href="#读取流程" class="headerlink" title="读取流程"></a>读取流程</h2><p><img src="http://img.hecenjie.cn/截屏2020-01-30下午4.39.01.png" alt="读取"></p><ol><li>应用程序调用GFS客户端提供的接口，指明文件名和字节偏移。</li><li>GFS客户端根据固定的Chunk大小将字节偏移转换成Chunk索引，然后将文件名和Chunk索引发送给Master节点。</li><li>Master节点将相应的Chunk ID和Chunk的位置信息响应给客户端（客户端此时用文件名和Chunk索引作为key缓存这些信息）。</li><li>GFS客户端向最近的持有副本的Chunk服务器发出读请求，请求中包含Chunk id与字节范围。</li></ol><p>在对这个Chunk的后续读取操作中，客户端不必再和Master节点通讯了，除非缓存的元数据信息过期或者文件被重新打开。</p><h2 id="写入流程"><a href="#写入流程" class="headerlink" title="写入流程"></a>写入流程</h2><p>GFS引入了租约（lease）机制。Master节点为Chunk的其中一个副本建立一个租约，这个副本就是Primary，Primary对Chunk的所有更改操作进行序列化，所有的副本都遵从这个序列进行修改操作。</p><p><img src="http://img.hecenjie.cn/截屏2020-01-31上午11.11.44.png" alt="写入"></p><ol><li>客户端向Master节点询问哪个Chunk服务器是Primary以及其它副本（Secondary）的位置，客户端在本地缓存这些信息。</li><li>客户端将数据链式推送到所有副本上。</li><li>客户端通知Primary提交。</li><li>Primary提交成功后，通知所有Secondary提交。</li><li>Secondary成功后响应Primary，Primary响应客户端。</li></ol><p>论文中说“设计租约机制的目的是为了最小化Master节点的管理负担”，刚开始未能理解其中的原因。实际上，由于租约的存在，客户端就不必每次进行写入时都询问Master由哪个Chunk服务器负责全局顺序，只要在租约的有效期内，客户端就可以一直联系该Chunk服务器，从而减轻了Master的负担。</p><p>为了提高网络效率，GFS还将数据流和控制流分开，并且数据在Chunk服务器间链式推送（每台机器都尽量选择最近的），从而充分利用每台机器的带宽，避免网络瓶颈和高延时的连接，最小化推送所有数据的延时。不同于主从模式对Primary的压力，这种链式模式下每台机器所有的出口带宽都用于以最快的速度传输数据。除此之外，GFS还使用TCP流式传输数据，即一旦Chunk服务器收到数据就立刻开始推送，而不用等收到完整的数据再发往下一个副本。</p><h2 id="一致性模型"><a href="#一致性模型" class="headerlink" title="一致性模型"></a>一致性模型</h2><p><img src="http://img.hecenjie.cn/截屏2020-01-31上午9.34.26.png" alt="一致性模型"></p><ul><li>一致的：对于文件区域A，如果所有客户端从任何副本上读到的数据都是相同的，那A就是一致的。</li><li>已定义的：如果A是一致的，并且客户端可以看到写入的完整数据，那A就是defined，即结果是可预期的。已定义一定是一致的。</li></ul><p>GFS所谓的宽松的一致性可能有点晦涩。<br>写操作（修改操作）包含覆盖写和追加写两种模式。覆盖写由用户指定offset，所以在并发写入时，可能各个用户写入的数据相互混合，我们就无从得知这一堆混合的数据里都是哪些操作分别写入了哪部分数据，但是由于操作在所有的副本上都以相同的顺序执行，读的时候确实是相同的结果，所以就是所谓的“一致但是未定义”。而对于追加写来说，offset是由GFS选择的，GFS保证操作“至少会成功一次”，这种重试机制导致了“已定义但部分不一致“的情况。举个例子，假设追加写操作在两个副本上都成功了，而在最后一个副本上失败了（这个时候仅仅是不一致），那么此时会尝试重试，并且那两个副本上的重复数据不会删除，当重试成功后，因为客户端能看到写入的完整数据，所以是“已定义的”，但由于中间夹杂着不一致的数据，所以是“部分不一致”的，但是对于这种部分不一致，可以通过Checksum或唯一标识符来解决。</p><h2 id="命名空间管理和锁"><a href="#命名空间管理和锁" class="headerlink" title="命名空间管理和锁"></a>命名空间管理和锁</h2><p>GFS的命名空间就是一个全路径和元数据映射关系的查找表，利用前缀压缩高效的存储在内存中。在存储命名空间的树形结构上，每个节点（绝对路径的文件名或绝对路径的目录名）都有一个关联的读写锁。通常情况下，如果一个操作涉及<code>/d1/d2/dn/leaf</code>，那么操作首先要获得目录<code>/d1</code>、<code>/d1/d2</code>、<code>/d1/d2/dn</code>的读锁和<code>/d1/d2/dn/leaf</code>的读写锁。一个操作必须按特定的顺序来申请锁以预防死锁：首先按命名空间树的层级排序，在相同层级再按字典序。</p><p>采用这种锁方案的优点是支持对同一目录的并行操作，目录名的读锁足以防止目录被删除、改名以及被快照，而文件名的写锁序列化了文件创建操作，确保不会多次创建同名的文件。</p><h2 id="垃圾回收"><a href="#垃圾回收" class="headerlink" title="垃圾回收"></a>垃圾回收</h2><p>GFS在删除文件时是惰性的，也就是说不会立刻回收可用的物理空间，而是像其它修改操作一样先以日志的方式记录，然后将文件名改为一个包含删除时间戳的隐藏文件。Master会定期对命名空间进行扫描，把隐藏了超过一定时间的文件删除（这个时间是可设置的），在此期间可以对这个文件进行恢复（重命名即可）。当隐藏文件从命名空间删除时，Master内存中这个文件的相关元数据才会被删除。Chunk服务器在和Master节点交互的心跳信息中，报告它拥有的Chunk子集的信息，Master节点回复Chunk服务器哪些Chunk在Master节点保存的元数据中已经不存在了，Chunk服务器可以任意删除这些Chunk的副本。</p><p>垃圾回收相比直接删除有几个优势：</p><ul><li>删除消息可能丢失，而垃圾回收方式简单可靠。</li><li>回收操作被合并到Master节点规律性的后台活动中，开销被分摊。</li><li>防止文件被意外删除。</li></ul><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/gfs-sosp2003.pdf" target="_blank" rel="noopener">The Google File System</a></li><li><a href="https://www.cnblogs.com/xybaby/p/8967424.html" target="_blank" rel="noopener">典型分布式系统分析: GFS</a></li><li><a href="https://kb.cnblogs.com/page/174130/" target="_blank" rel="noopener">经典论文翻译导读之《Google File System》</a></li><li><a href="https://juejin.im/post/5d9dc4d2e51d4578453274cd#fn1" target="_blank" rel="noopener">The Google File System 论文笔记</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;p&gt;Google File System（简称GFS）是一个面向大规模数据密集型应用的、可伸缩的分布式文件系统，其运行在廉价的普通硬件设备上，并
      
    
    </summary>
    
    
      <category term="分布式" scheme="http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>分布式一致性协议：2PC与3PC</title>
    <link href="http://yoursite.com/2019/10/27/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7%E5%8D%8F%E8%AE%AE%EF%BC%9A2PC%E4%B8%8E3PC/"/>
    <id>http://yoursite.com/2019/10/27/分布式一致性协议：2PC与3PC/</id>
    <published>2019-10-27T12:29:00.000Z</published>
    <updated>2019-10-27T14:02:58.359Z</updated>
    
    <content type="html"><![CDATA[<h2 id="协调者"><a href="#协调者" class="headerlink" title="协调者"></a>协调者</h2><p>在分布式系统中，每一个机器节点虽然都能明确的知道自己执行的事务是成功还是失败，但是却无法知道其他分布式节点的事务执行情况。因此，当一个事务要跨越多个分布式节点的时候（比如，淘宝下单流程，下单系统和库存系统可能就是分别部署在不同的分布式节点中），为了保证该事务可以满足ACID，就要引入一个协调者（Cooradinator）。其他的节点被称为参与者（Participant）。协调者负责调度参与者的行为，并最终决定这些参与者是否要把事务进行提交。</p><h2 id="二阶段提交协议（2PC）"><a href="#二阶段提交协议（2PC）" class="headerlink" title="二阶段提交协议（2PC）"></a>二阶段提交协议（2PC）</h2><p>二阶段提交协议主要分为两个阶段：准备阶段和提交阶段。</p><h3 id="准备阶段"><a href="#准备阶段" class="headerlink" title="准备阶段"></a>准备阶段</h3><p>事务协调者（事务管理器）给每个参与者发送事务内容，每个参与者要么直接返回失败（如权限验证失败），要么在本地执行事务，写本地的redo和undo日志，但不提交，到达一种“万事俱备，只欠东风”的状态。由于这一阶段近似各参与者投票表明是否可以执行接下来的事务提交操作，所以也被称为“投票阶段”。</p><h3 id="提交阶段"><a href="#提交阶段" class="headerlink" title="提交阶段"></a>提交阶段</h3><p>如果协调者收到了参与者的失败消息或者超时，直接给每个参与者发送回滚（Rollback）消息；否则，发送提交（Commit）消息；参与者根据协调者的指令执行提交或者回滚操作，释放所有事务处理过程中使用的锁资源。</p><h3 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h3><p>优点：原理简单、实现方便。<br>缺点：</p><ul><li>同步阻塞：各个参与者在等待其他参与者响应的过程中，将无法进行其他任何操作。</li><li>单点问题：协调者至关重要。尤其在第二阶段，协调者发生故障，那么所有的参与者还都处于锁定事务资源的状态中，而无法继续完成事务操作。</li><li>数据不一致：由于参与者可能宕机，此时只有部分参与者收到了commit请求。</li></ul><h2 id="三阶段提交协议（3PC）"><a href="#三阶段提交协议（3PC）" class="headerlink" title="三阶段提交协议（3PC）"></a>三阶段提交协议（3PC）</h2><p>3PC在协调者和参与者中都引入了超时机制，并将2PC的准备阶段（投票阶段）一分为二，这样三阶段提交就有CanCommit、PreCommit、DoCommit三个阶段。</p><h3 id="CanCommit阶段"><a href="#CanCommit阶段" class="headerlink" title="CanCommit阶段"></a>CanCommit阶段</h3><p>协调者向所有的参与者发送一个包含事务内容的CanCommit请求，参与者在收到该请求后，如果认为自己可以顺利执行事务，就反馈Yes响应，并进入预备状态，否则反馈No响应。</p><h3 id="PreCommit阶段"><a href="#PreCommit阶段" class="headerlink" title="PreCommit阶段"></a>PreCommit阶段</h3><p>协调者根据参与者的反馈情况来决定是否可以继续事务的PreCommit操作。根据响应情况，有以下两种可能。</p><ul><li>假如协调者从所有的参与者获得的反馈都是Yes响应，那么就会执行事务的预执行。即执行事务操作，并将undo和redo信息记录到事务日志中。如果参与者成功的执行了事务操作，则返回Ack响应，同时开始等待最终指令。</li><li>假如有任何一个参与者向协调者发送了No响应，或者等待超时之后，协调者都没有接到参与者的响应，那么就执行事务的中断。</li></ul><h3 id="DoCommit阶段"><a href="#DoCommit阶段" class="headerlink" title="DoCommit阶段"></a>DoCommit阶段</h3><p>该阶段进行真正的事务提交，也可以分为以下两种情况。</p><ul><li>执行提交：协调者接收到参与者发送的ACK响应，那么他将从预提交状态进入到提交状态，并向所有参与者发送doCommit请求。参与者接收到doCommit请求之后，执行正式的事务提交，并在完成事务提交之后释放所有事务资源，并向协调者发送Ack响应。协调者接收到所有参与者的ack响应之后，完成事务。</li><li>中断事务：协调者没有接收到参与者发送的Ack响应（可能是接受者发送的不是Ack响应，也可能响应超时），那么就会执行中断事务，即回滚操作。</li></ul><blockquote><p>在doCommit阶段，如果参与者无法及时接收到来自协调者的doCommit或者rebort请求时，会在等待超时之后，会继续进行事务的提交。（其实这个应该是基于概率来决定的，当进入第三阶段时，说明参与者在第二阶段已经收到了PreCommit请求，那么协调者产生PreCommit请求的前提条件是他在第二阶段开始之前，收到所有参与者的CanCommit响应都是Yes。（一旦参与者收到了PreCommit，意味他知道大家其实都同意修改了）所以，一句话概括就是，当进入第三阶段时，由于网络超时等原因，虽然参与者没有收到commit或者abort响应，但是他有理由相信：成功提交的几率很大。 ）</p></blockquote><h3 id="优缺点-1"><a href="#优缺点-1" class="headerlink" title="优缺点"></a>优缺点</h3><p>优点：降低了参与者的阻塞范围，比如在执行事务之前先询问是否可以顺利执行，避免一些本来就无法执行的参与者导致其他正常的参与者无意义的回滚。并且由于一旦参与者无法及时收到来自协调者的信息之后，他会默认执行commit，因此也就解决了单点故障问题。<br>缺点：超时机制虽然解决了单点问题，但也引入了数据不一致的问题，比如协调者发送的abort响应没有及时被参与者接收到，那么参与者在等待超时之后执行了commit操作，这样就和其他接到abort命令并执行回滚的参与者之间存在数据不一致的情况。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li>从 Paxos 到 ZooKeeper 分布式一致性原理与实践.倪超.电子工业出版社</li><li><a href="https://www.hollischuang.com/archives/681" target="_blank" rel="noopener">关于分布式事务、两阶段提交协议、三阶提交协议</a></li><li><a href="https://www.hollischuang.com/archives/1580" target="_blank" rel="noopener">深入理解分布式系统的2PC和3PC</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;协调者&quot;&gt;&lt;a href=&quot;#协调者&quot; class=&quot;headerlink&quot; title=&quot;协调者&quot;&gt;&lt;/a&gt;协调者&lt;/h2&gt;&lt;p&gt;在分布式系统中，每一个机器节点虽然都能明确的知道自己执行的事务是成功还是失败，但是却无法知道其他分布式节点的事务执行情况。因此，当一
      
    
    </summary>
    
      <category term="分布式系统" scheme="http://yoursite.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="分布式系统" scheme="http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="一致性协议" scheme="http://yoursite.com/tags/%E4%B8%80%E8%87%B4%E6%80%A7%E5%8D%8F%E8%AE%AE/"/>
    
  </entry>
  
  <entry>
    <title>CAP与BASE理论</title>
    <link href="http://yoursite.com/2019/10/27/CAP%E4%B8%8EBASE%E7%90%86%E8%AE%BA/"/>
    <id>http://yoursite.com/2019/10/27/CAP与BASE理论/</id>
    <published>2019-10-27T12:06:00.000Z</published>
    <updated>2019-10-28T01:34:27.418Z</updated>
    
    <content type="html"><![CDATA[<h2 id="CAP定理"><a href="#CAP定理" class="headerlink" title="CAP定理"></a>CAP定理</h2><p>一个分布式系统不可能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三个基本需求，最多只能满足其中的两项.</p><p>一般情况下，分区容错性是一个最基本的要求，其次才在可用性和一致性之间作出取舍。</p><blockquote><p>一致性模型：</p><ul><li>弱一致性<ul><li>最终一致性：DNS、Gossip协议</li></ul></li><li>强一致性<ul><li>同步</li><li>Paxos</li><li>Raft</li><li>ZAB</li></ul></li></ul></blockquote><h2 id="BASE理论"><a href="#BASE理论" class="headerlink" title="BASE理论"></a>BASE理论</h2><p>BASE是Basically Available（基本可用）、Soft state（软状态）、Eventually Consistent（最终一致性）三个短语的简称，是对CAP中一致性和可用性权衡的结果，核心思想是即使无法做到强一致性，但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性。</p><blockquote><p>基本可用：分布式系统在出现不可预知故障时，允许损失部分可用性。<br>弱状态：即软状态，允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性。<br>最终一致性：系统保证数据最终能够达到一致，而不需要实时保证系统数据的强一致性。</p></blockquote><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li>从 Paxos 到 ZooKeeper 分布式一致性原理与实践.倪超.电子工业出版社</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;CAP定理&quot;&gt;&lt;a href=&quot;#CAP定理&quot; class=&quot;headerlink&quot; title=&quot;CAP定理&quot;&gt;&lt;/a&gt;CAP定理&lt;/h2&gt;&lt;p&gt;一个分布式系统不可能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Par
      
    
    </summary>
    
      <category term="分布式系统" scheme="http://yoursite.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="CAP" scheme="http://yoursite.com/tags/CAP/"/>
    
      <category term="BASE" scheme="http://yoursite.com/tags/BASE/"/>
    
      <category term="分布式系统" scheme="http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>僵尸进程与孤儿进程</title>
    <link href="http://yoursite.com/2019/07/20/%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%AD%A4%E5%84%BF%E8%BF%9B%E7%A8%8B/"/>
    <id>http://yoursite.com/2019/07/20/僵尸进程与孤儿进程/</id>
    <published>2019-07-20T11:24:00.000Z</published>
    <updated>2019-07-20T12:02:22.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="僵尸进程"><a href="#僵尸进程" class="headerlink" title="僵尸进程"></a>僵尸进程</h2><p>一个父进程利用<code>fork</code>创建子进程，如果子进程结束了，但是父进程没有等待（调用<code>wait</code> / <code>waitpid</code>）它，那么该子进程将变成一个僵尸进程。</p><p>僵尸进程对操作系统是有害的：在每个进程退出的时候，内核释放该进程所有的资源，包括打开的文件、占用的内存等，但是仍然为其保留一定的信息（包括进程号、退出状态、运行时间等），如果父进程一直不调用<code>wait</code> / <code>waitpid</code>，那么保留的这些信息就不会释放，其进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果产生大量的僵尸进程，将因为没有可用的进程号而导致系统不能产生新的进程。</p><h2 id="孤儿进程"><a href="#孤儿进程" class="headerlink" title="孤儿进程"></a>孤儿进程</h2><p>一个父进程退出，而它的一个或多个子进程仍然在运行，那么这些子进程就会变成孤儿进程。孤儿进程将被init进程（进程号为1）所收养，init进程将在这些孤儿进程结束时第一时间回收它们的信息，保证它们不会成为僵尸进程。</p><h2 id="僵尸进程的避免"><a href="#僵尸进程的避免" class="headerlink" title="僵尸进程的避免"></a>僵尸进程的避免</h2><ul><li>父进程通过<code>wait</code> / <code>waitpid</code>等待子进程，子进程工作完父进程再执行工作。</li><li>父进程<code>fork</code>一个子进程，然后继续工作，子进程<code>fork</code>一个孙进程后退出，那么孙进程将变为孤儿进程从而被<code>init</code>接管，并且由孙进程接受本应子进程接受的任务。当孙进程结束后，<code>init</code>会回收它的信息，不过子进程的回收还是需要自己做。</li></ul><h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><p>僵尸状态是每个子进程必经的状态，而之所以在进程结束后要进入僵尸状态是因为父进程可能要取得子进程的退出状态等信息。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;僵尸进程&quot;&gt;&lt;a href=&quot;#僵尸进程&quot; class=&quot;headerlink&quot; title=&quot;僵尸进程&quot;&gt;&lt;/a&gt;僵尸进程&lt;/h2&gt;&lt;p&gt;一个父进程利用&lt;code&gt;fork&lt;/code&gt;创建子进程，如果子进程结束了，但是父进程没有等待（调用&lt;code&gt;wait&lt;
      
    
    </summary>
    
      <category term="操作系统" scheme="http://yoursite.com/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="Linux" scheme="http://yoursite.com/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>关于Java和Python的一些思考</title>
    <link href="http://yoursite.com/2019/05/30/%E5%85%B3%E4%BA%8EJava%E5%92%8CPython%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/"/>
    <id>http://yoursite.com/2019/05/30/关于Java和Python的一些思考/</id>
    <published>2019-05-30T11:37:00.000Z</published>
    <updated>2019-05-30T12:29:00.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>最近实习在做的一些项目都是用Python来写的，虽然在之前就有学习过Python的语法，但真正用到的机会很少，而这次通过项目刚好让我对Python有了更进一步的认识，并且在此总结一下Python与之前用的比较多的Java的一些区别。</p><h2 id="动态类型"><a href="#动态类型" class="headerlink" title="动态类型"></a>动态类型</h2><p>Python与Java很大的一个区别在于Java必须在第一次声明变量时指定其类型，也就是所谓的静态类型，而Python则不一样，Python可以动态改变变量的类型。虽然Python的这个特性显得十分灵活，并且某些场景下可能开发效率更高一些，但稍不注意的话就有可能出错，在写代码时要更加注意。</p><h2 id="缩进"><a href="#缩进" class="headerlink" title="缩进"></a>缩进</h2><p>Python不像很多语言使用花括号定义函数或类，而是使用的缩进将代码分割成块，使得代码可读性更高一些。</p><h2 id="GIL"><a href="#GIL" class="headerlink" title="GIL"></a>GIL</h2><p>因为在项目中有许多要异步执行的任务，如果不了解Python的话，可能就会想到用多线程来解决问题，但实际上，Python中并不存在真正意义上的多线程，原因就是GIL的存在。GIL即全局解释器锁，Python的每个线程运行时首先要获得该锁，这也就意味着任何时刻仅有一个线程在执行，无法利用到多核的优势，使得多线程的效率甚至还不如单线程。但这也并非绝对的，在I/O操作或别的一些情况下，线程会主动释放GIL，这样别的线程就可以继续工作了，而如果是想完成一些CPU密集的任务的话，就只能通过进程或协程来解决了。</p><h2 id="垃圾收集"><a href="#垃圾收集" class="headerlink" title="垃圾收集"></a>垃圾收集</h2><p>不像Java使用的可达性分析算法，Python中的垃圾收集是使用的引用计数法，这也就意味着会有循环引用的问题。比如说，在以下这个代码中：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f2</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        c1=ClassA()</span><br><span class="line">        c2=ClassA()</span><br><span class="line">        c1.t=c2</span><br><span class="line">        c2.t=c1</span><br><span class="line">        <span class="keyword">del</span> c1</span><br><span class="line">        <span class="keyword">del</span> c2</span><br></pre></td></tr></table></figure></p><p>在执行完上面的代码后，两个对象的引用计数都为1而非0，虽然它们都应该要被回收销毁的，但由于存在循环引用，所以不会被回收掉，也就导致了内存泄露。要解决这个问题，可以使用gc模块。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;最近实习在做的一些项目都是用Python来写的，虽然在之前就有学习过Python的语法，但真正用到的机会很少，而这次通过项目刚好让我对Pyt
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>常见查找算法之跳跃表</title>
    <link href="http://yoursite.com/2019/05/28/%E5%B8%B8%E8%A7%81%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95%E4%B9%8B%E8%B7%B3%E8%B7%83%E8%A1%A8/"/>
    <id>http://yoursite.com/2019/05/28/常见查找算法之跳跃表/</id>
    <published>2019-05-28T12:06:00.000Z</published>
    <updated>2022-03-02T07:56:44.204Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>跳跃表（skiplist）是一种有序数据结构，它通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的。</p><p>跳跃表支持平均O(logN)和最坏O(N)复杂度的节点查找，还可以通过顺序性操作来批量处理节点。在大部分情况下，跳跃表的效率可以和平衡树相媲美，并且因为跳跃表的实现比平衡树要来得更为简单，所以有不少程序都使用跳跃表来代替平衡树。</p><h2 id="跳跃表的实现"><a href="#跳跃表的实现" class="headerlink" title="跳跃表的实现"></a>跳跃表的实现</h2><p>Redis的跳跃表由<code>zskiplistNode</code>和<code>zskiplist</code>两个结构定义，其中<code>zskiplistNode</code>结构用于表示跳跃表节点，而<code>zskiplist</code>结构则用于保存跳跃表节点的相关信息，比如节点的数量，以及指向表头节点和表尾节点的指针等等。</p><p><img src="http://img.hecenjie.cn/graphviz-8fc5de396a5b52c3d0b1991a1e09558ad055dd86.png" alt></p><p>图5-1展示了一个跳跃表示例，位于图片最左边的是<code>zskiplist</code>结构，该结构包含以下属性：</p><ul><li><code>header</code>：指向跳跃表的表头节点。</li><li><code>tail</code>：指向跳跃表的表尾节点。</li><li><code>level</code>：记录目前跳跃表内，层数最大的那个节点的层数（表头节点的层数不计算在内）。</li><li><code>length</code>：记录跳跃表的长度，也即是，跳跃表目前包含节点的数量（表头节点不计算在内）。</li></ul><p>位于<code>zskiplist</code>结构右方的是四个<code>zskiplistNode</code>结构，该结构包含以下属性：</p><ul><li>层（level）：节点中用 L1 、 L2 、 L3 等字样标记节点的各个层，L1 代表第一层， L2 代表第二层，以此类推。每个层都带有两个属性：前进指针和跨度。前进指针用于访问位于表尾方向的其他节点，而跨度则记录了前进指针所指向节点和当前节点的距离。每次创建一个新跳跃表节点的时候， 程序都根据幂次定律（power law，越大的数出现的概率越小）随机生成一个介于1和32之间的值作为层的高度。跨度是用来计算排位（rank）的，在查找某个节点的过程中，将沿途访问过的所有层的跨度累计起来，得到的结果就是目标节点在跳跃表中的排位。</li><li>后退（backward）指针：节点中用 BW 字样标记节点的后退指针，它指向位于当前节点的前一个节点。后退指针在程序从表尾向表头遍历时使用。跟可以一次跳过多个节点的前进指针不同，因为每个节点只有一个后退指针，所以每次只能后退至前一个节点。</li><li>分值（score）：各个节点中的 1.0 、 2.0 和 3.0 是节点所保存的分值。在跳跃表中，节点按各自所保存的分值从小到大排列。</li><li>成员对象（obj）：各个节点中的 o1、o2 和 o3 是节点所保存的成员对象。分值相同的节点将按照成员对象在字典序中的大小来进行排序，成员对象较小的节点会排在前面，而成员对象较大的节点则会排在后面。</li></ul><p>注意表头节点和其他节点的构造是一样的：表头节点也有后退指针、分值和成员对象，不过表头节点的这些属性都不会被用到，所以图中省略了这些部分，只显示了表头节点的各个层。</p><p>虽然仅靠多个跳跃表节点就可以组成一个跳跃表，但通过使用一个<code>zskiplist</code>结构来持有这些节点，程序可以更方便地对整个跳跃表进行处理，比如快速访问跳跃表的表头节点和表尾节点，又或者快速地获取跳跃表节点的数量（也即是跳跃表的长度）等信息。</p><h3 id="查找"><a href="#查找" class="headerlink" title="查找"></a>查找</h3><p>跳跃表的查找是从最上层的跳跃区间大的层开始的，从头结点开始和前进指针指向的节点进行比较，如果大于前进节点，则继续向前找，如果小于前进节点，则到下一层继续查找，直到找到为止。</p><h3 id="插入"><a href="#插入" class="headerlink" title="插入"></a>插入</h3><p>跳跃表的插入操作和链表的插入操作十分相似，大致过程如下：</p><ol><li>查找到需要插入的位置</li><li>申请新的结点</li><li>调整指针</li></ol><p>因为找到插入点之后，新生成节点，新节点的层的高度是随机生成的，故需要保存所有层的后继指针。</p><h3 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h3><p>删除和插入类似，大致过程如下：</p><ol><li>查找到需要删除的结点 </li><li>删除结点</li><li>调整指针</li></ol><h3 id="时间复杂度"><a href="#时间复杂度" class="headerlink" title="时间复杂度"></a>时间复杂度</h3><ul><li>最坏时间复杂度 О(n)</li><li>平均时间复杂度 O(logn)</li></ul><h2 id="Redis中的应用"><a href="#Redis中的应用" class="headerlink" title="Redis中的应用"></a>Redis中的应用</h2><p>Redis使用跳跃表作为有序集合键的底层实现之一：如果一个有序集合包含的元素数量比较多，又或者有序集合中元素的成员是比较长的字符串时，Redis就会使用跳跃表来作为有序集合键的底层实现。而之所以不使用红黑树，是因为在性能相差不大的情况下，跳跃表实现更为简单。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>跳跃表是有序集合的底层实现之一。</li><li>Redis的跳跃表实现由<code>zskiplist</code>和<code>zskiplistNode</code>两个结构组成，其中<code>zskiplist</code>用于保存跳跃表信息（比如表头节点、表尾节点、长度），而<code>zskiplistNode</code>则用于表示跳跃表节点。</li><li>每个跳跃表节点的层高都是1至32之间的随机数。</li><li>在同一个跳跃表中，多个节点可以包含相同的分值，但每个节点的成员对象必须是唯一的。</li><li>跳跃表中的节点按照分值大小进行排序，当分值相同时，节点按照成员对象的大小进行排序。</li></ul><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="http://redisbook.com/preview/skiplist/datastruct.html" target="_blank" rel="noopener">Redis 设计与实现</a></li><li><a href="https://blog.csdn.net/yang_yulei/article/details/46275283" target="_blank" rel="noopener">查找——图文翔解SkipList（跳跃表）</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;跳跃表（skiplist）是一种有序数据结构，它通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的。&lt;/p&gt;
&lt;p&gt;跳跃
      
    
    </summary>
    
      <category term="算法" scheme="http://yoursite.com/categories/%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="Redis" scheme="http://yoursite.com/tags/Redis/"/>
    
      <category term="跳跃表" scheme="http://yoursite.com/tags/%E8%B7%B3%E8%B7%83%E8%A1%A8/"/>
    
  </entry>
  
  <entry>
    <title>Drools规则引擎原理简介</title>
    <link href="http://yoursite.com/2019/05/28/Drools%E8%A7%84%E5%88%99%E5%BC%95%E6%93%8E%E5%8E%9F%E7%90%86%E7%AE%80%E4%BB%8B/"/>
    <id>http://yoursite.com/2019/05/28/Drools规则引擎原理简介/</id>
    <published>2019-05-28T08:21:00.000Z</published>
    <updated>2022-03-02T07:56:58.343Z</updated>
    
    <content type="html"><![CDATA[<h2 id="DRL解释执行流程"><a href="#DRL解释执行流程" class="headerlink" title="DRL解释执行流程"></a>DRL解释执行流程</h2><p>Drools 规则是在 Java 应用程序上运行的，其要执行的步骤顺序由代码确定。为了实现这一点，Drools 规则引擎将业务规则转换成执行树，如下图所示：<br><img src="http://img.hecenjie.cn/20170709223809798.jpg" alt><br>如上图所示，每个规则条件分为小块，在树结构中连接和重用。每次将数据添加到规则引擎中时，它将在与此类似的树中进行求值，并到达一个动作节点，在该节点处，它们将被标记为准备执行特定规则的数据。</p><h2 id="规则引擎工作方式"><a href="#规则引擎工作方式" class="headerlink" title="规则引擎工作方式"></a>规则引擎工作方式</h2><p>Drools规则引擎基于ReteOO算法（对面向对象系统的Rete算法进行了增强和优化的实现），它将事实（<code>Fact</code>）与规则进行匹配，以推断相应的规则结果，这个过程称之为模式匹配。</p><p><img src="http://img.hecenjie.cn/20170709223935035.jpg" alt></p><p>当我们到达一个事实（<code>Fact</code>）与规则相匹配的节点时，规则评估会将规则操作与触发数据添加到一个叫作议程（<code>Agenda</code>）的组件中，如果同一个事实（<code>Fact</code>）与多个规则相匹配，就认为这些规则是冲突的，议程（<code>Agenda</code>）使用冲突解决策略（<code>Conflict Resolution strategy</code>）管理这些冲突规则的执行顺序。整个生命周期中，规则评估与规则执行之间有着明确的分割。规则操作的执行可能会导致事实（<code>Fact</code>）的更新，从而与其它规则相匹配，导致它们的触发，称之为前向链接。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://blog.csdn.net/chinrui/article/details/74906748" target="_blank" rel="noopener">Drools 简介</a></li><li><a href="https://blog.csdn.net/lfsf802/article/details/42297469" target="_blank" rel="noopener">rete算法学习</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;DRL解释执行流程&quot;&gt;&lt;a href=&quot;#DRL解释执行流程&quot; class=&quot;headerlink&quot; title=&quot;DRL解释执行流程&quot;&gt;&lt;/a&gt;DRL解释执行流程&lt;/h2&gt;&lt;p&gt;Drools 规则是在 Java 应用程序上运行的，其要执行的步骤顺序由代码确定。为
      
    
    </summary>
    
    
      <category term="Drools" scheme="http://yoursite.com/tags/Drools/"/>
    
  </entry>
  
  <entry>
    <title>工厂模式与模板方法的一次实践</title>
    <link href="http://yoursite.com/2019/05/28/%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%E4%B8%8E%E6%A8%A1%E6%9D%BF%E6%96%B9%E6%B3%95%E7%9A%84%E4%B8%80%E6%AC%A1%E5%AE%9E%E8%B7%B5/"/>
    <id>http://yoursite.com/2019/05/28/工厂模式与模板方法的一次实践/</id>
    <published>2019-05-28T06:26:00.000Z</published>
    <updated>2022-03-02T07:57:14.654Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>最近做的一个项目是实现一个灰度发布的逻辑，具体来说就是当某个产品更新的时候，根据不同的用户决定是否对新版本可见。该功能本身是很容易实现的，但是考虑到可扩展性的问题，引入了Drools规则引擎，并且通过一些设计模式来进一步提高它的可扩展性，以应对之后可能不断发生变化的规则。</p><h2 id="原始代码"><a href="#原始代码" class="headerlink" title="原始代码"></a>原始代码</h2><p>由于规则并不十分复杂，所以项目中将许多的校验与判断逻辑统一封装到了Fact对象中，而在.drl文件中仅仅是做一些初始化工作，例如这里的场景是给每个用户设置一个新版本可见的延迟天数，达到了这个天数才能获取新版本，那么在.drl中就是将用户与延迟天数的映射关系做初始化。因此，最开始只需要一个Fact就行了：<br><img src="http://img.hecenjie.cn/DelayDaysPatternReleaseFact.png" alt><br>在.drl文件中，初始化完成之后，仅仅需要调用这个Fact对象的<code>releaseCheck()</code>，然后就可以通过<code>isRelease()</code>方法决定是否发布新版本了。</p><h2 id="可扩展性"><a href="#可扩展性" class="headerlink" title="可扩展性"></a>可扩展性</h2><p>由上面的简单分析可以看到，判断是否发布新版本的逻辑都封装在了<code>releaseCheck()</code>方法中，但这个方法中的许多步骤其实是冗余的，比如说参数校验、安全校验等等，如果每次增加新的Fact时都去写一模一样的重复代码，就显得十分不简洁且不利于维护了，因此，我们将该方法抽象出来，并且将其中最关键的判断逻辑<code>doReleaseCheck()</code>交由子类去实现，这样不同的Fact子类只需要实现各自的核心判断逻辑即可。此时的UML如下：<br><img src="http://img.hecenjie.cn/PatternReleaseFact.png" alt><br>除此之外，对于调用方来说，是不需要关心Fact对象的创建过程的，尤其是当参数比较复杂的情况下。这时候就可以通过工厂方法模式，将创建对象的具体过程交给工厂类来完成：<br><img src="http://img.hecenjie.cn/PatternReleaseFactFactory.png" alt><br>这样，对于调用方来说，只需要传入一个<code>UserInfo</code>对象即可，具体需要用到它的哪些属性以及属性的一些校验工作则交由工厂类来实现，调用方可以直接拿到想要的Fact对象。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>通过模板方法，可以在抽象父类中先定义好整个方法的框架，并且让不同的子类去实现其中的某些核心步骤，这些核心步骤在父类中是抽象的；而通过工厂方法，使得调用者不再需要关心创建对象的具体过程，将许多繁琐的工作解耦了出去，由工厂类来负责实现。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;最近做的一个项目是实现一个灰度发布的逻辑，具体来说就是当某个产品更新的时候，根据不同的用户决定是否对新版本可见。该功能本身是很容易实现的，但
      
    
    </summary>
    
      <category term="项目" scheme="http://yoursite.com/categories/%E9%A1%B9%E7%9B%AE/"/>
    
    
      <category term="项目" scheme="http://yoursite.com/tags/%E9%A1%B9%E7%9B%AE/"/>
    
      <category term="工厂方法" scheme="http://yoursite.com/tags/%E5%B7%A5%E5%8E%82%E6%96%B9%E6%B3%95/"/>
    
      <category term="模板方法" scheme="http://yoursite.com/tags/%E6%A8%A1%E6%9D%BF%E6%96%B9%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>MySQL建索引的几大原则</title>
    <link href="http://yoursite.com/2019/05/27/%E5%BB%BA%E7%B4%A2%E5%BC%95%E7%9A%84%E5%87%A0%E5%A4%A7%E5%8E%9F%E5%88%99/"/>
    <id>http://yoursite.com/2019/05/27/建索引的几大原则/</id>
    <published>2019-05-27T14:28:00.000Z</published>
    <updated>2019-05-27T14:32:18.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="最左前缀匹配原则"><a href="#最左前缀匹配原则" class="headerlink" title="最左前缀匹配原则"></a>最左前缀匹配原则</h2><p>b+树的数据项是复合的数据结构，比如索引为<code>(name, age, sex)</code>的时候，b+数是按照从左到右的顺序来建立搜索树的，比如当<code>(张三, 20, F)</code>这样的数据来检索的时候，b+树会优先比较<code>name</code>来确定下一步的搜索方向，如果<code>name</code>相同再依次比较<code>age</code>和<code>sex</code>，最后得到检索的数据；但当<code>(20, F)</code>这样的没有<code>name</code>的数据来的时候，b+树就不知道下一步该查哪个节点，因为建立搜索树的时候<code>name</code>就是第一个比较因子，必须要先根据<code>name</code>来搜索才能知道下一步去哪里查询。比如当<code>(张三, F)</code>这样的数据来检索时，b+树可以用<code>name</code>来指定搜索方向，但下一个字段<code>age</code>的缺失，所以只能把名字等于张三的数据都找到，然后再匹配性别是<code>F</code>的数据了，这个是非常重要的性质，即索引的最左前缀匹配原则。</p><h2 id="索引建议"><a href="#索引建议" class="headerlink" title="索引建议"></a>索引建议</h2><ol><li>根据最左前缀匹配原则，MySQL会一直向右匹配直到遇到范围查询（<code>&gt;</code>、<code>&lt;</code>、<code>between</code>、<code>like</code>）就停止匹配，比如<code>a = 1 and b = 2 and c &gt; 3 and d = 4</code>，如果建立<code>(a, b, c, d)</code>顺序的索引，<code>d</code>是用不到索引的，如果建立<code>(a, b, d, c)</code>的索引则都可以用到，<code>a</code>、<code>b</code>、<code>d</code>的顺序可以任意调整。</li><li><code>=</code>和<code>in</code>可以乱序，比如<code>a = 1 and b = 2 and c = 3</code>建立<code>(a, b, c)</code>索引可以任意顺序，MySQL的查询优化器会帮你优化成索引可以识别的形式。</li><li>尽量选择区分度高的列作为索引，区分度的公式是<code>count(distinct col)/count(*)</code>，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就是0。</li><li>索引列不能参与计算，否则将导致引擎放弃使用索引而进行全表扫描，比如<code>select id from t where num/2=100;</code>应优化成<code>select id from t where num=100*2;</code></li><li>尽量的扩展索引，不要新建索引。比如表中已经有<code>a</code>的索引，现在要加<code>(a, b)</code>的索引，那么只需要修改原来的索引即可。</li></ol><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://tech.meituan.com/2014/06/30/mysql-index.html" target="_blank" rel="noopener">MySQL索引原理及慢查询优化</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;最左前缀匹配原则&quot;&gt;&lt;a href=&quot;#最左前缀匹配原则&quot; class=&quot;headerlink&quot; title=&quot;最左前缀匹配原则&quot;&gt;&lt;/a&gt;最左前缀匹配原则&lt;/h2&gt;&lt;p&gt;b+树的数据项是复合的数据结构，比如索引为&lt;code&gt;(name, age, sex)&lt;/c
      
    
    </summary>
    
      <category term="MySQL" scheme="http://yoursite.com/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="http://yoursite.com/tags/MySQL/"/>
    
      <category term="索引" scheme="http://yoursite.com/tags/%E7%B4%A2%E5%BC%95/"/>
    
  </entry>
  
  <entry>
    <title>InnoDB的行锁与表锁</title>
    <link href="http://yoursite.com/2019/05/27/InnoDB%E7%9A%84%E8%A1%8C%E9%94%81%E4%B8%8E%E8%A1%A8%E9%94%81/"/>
    <id>http://yoursite.com/2019/05/27/InnoDB的行锁与表锁/</id>
    <published>2019-05-27T12:21:00.000Z</published>
    <updated>2019-05-27T14:29:24.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在数据库系统中，根据作用范围我们可以将锁分为行级锁与表级锁，下面结合InnoDB与MyISAM引擎分别介绍一下这两种锁。</p><h2 id="表级锁"><a href="#表级锁" class="headerlink" title="表级锁"></a>表级锁</h2><p>表级锁是MySQL中锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少，但发出锁冲突的概率最高，并发度也是最低的。MyISAM就是使用的表级锁，并且因为MyISAM总是一次性获得所需的全部锁，要么全部满足，要么全部等待，所以是不会发生死锁的。</p><h2 id="行级锁"><a href="#行级锁" class="headerlink" title="行级锁"></a>行级锁</h2><p>行级锁是MySQL中锁定粒度最小的一种锁，表示只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突，其加锁粒度最小，但加锁的开销也最大。行级锁分为共享锁和排他锁。</p><h2 id="InnoDB中的行锁与表锁"><a href="#InnoDB中的行锁与表锁" class="headerlink" title="InnoDB中的行锁与表锁"></a>InnoDB中的行锁与表锁</h2><p>InnoDB行锁是通过给索引上的索引项加锁来实现的，这一点MySQL与Oracle不同，后者是通过在数据块中对相应数据行加锁来实现的。InnoDB这种行锁实现特点意味着只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表级锁。除此之外，虽然是访问不同行的记录，但是如果使用相同的索引键，是会出现锁冲突的。但如果MySQL认为全表扫描效率更高，比如对一些很小的表，它就不会使用索引，这种情况下InnoDB将使用表锁，而不是行锁。</p><p>在实际应用中，要特别注意InnoDB行锁的这一特性，不然的话，可能导致大量的锁冲突，从而影响并发性能。</p><h2 id="行级锁与死锁"><a href="#行级锁与死锁" class="headerlink" title="行级锁与死锁"></a>行级锁与死锁</h2><p>InnoDB与MyISAM不同，它是遵循的两段锁协议，是逐步获取锁的，也就有可能出现死锁问题。前面说过，InnoDB不是锁记录，而是锁索引。索引分为主键索引和非主键索引两种，如果一条SQL语句操作了主键索引，MySQL就会锁定这条主键索引；如果一条语句操作了非主键索引，MySQL会先锁定该非主键索引，再锁定相关的主键索引。当两个事务同时执行，一个锁住了主键索引，在等待其他相关索引。另一个锁定了非主键索引，在等待主键索引。这样就会发生死锁。发生死锁后，InnoDB一般都可以检测到，并使一个事务释放锁回退，另一个获取锁完成事务。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="http://www.hollischuang.com/archives/914" target="_blank" rel="noopener">MySQL中的行级锁,表级锁,页级锁</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;在数据库系统中，根据作用范围我们可以将锁分为行级锁与表级锁，下面结合InnoDB与MyISAM引擎分别介绍一下这两种锁。&lt;/p&gt;
&lt;h2 i
      
    
    </summary>
    
      <category term="MySQL" scheme="http://yoursite.com/categories/MySQL/"/>
    
    
      <category term="InnoDB" scheme="http://yoursite.com/tags/InnoDB/"/>
    
      <category term="MySQL" scheme="http://yoursite.com/tags/MySQL/"/>
    
      <category term="锁" scheme="http://yoursite.com/tags/%E9%94%81/"/>
    
  </entry>
  
  <entry>
    <title>MySQL主从复制与分库分表</title>
    <link href="http://yoursite.com/2019/05/27/MySQL%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E4%B8%8E%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB/"/>
    <id>http://yoursite.com/2019/05/27/MySQL主从复制与读写分离/</id>
    <published>2019-05-27T09:12:38.000Z</published>
    <updated>2022-03-02T07:57:40.689Z</updated>
    
    <content type="html"><![CDATA[<h2 id="主从复制"><a href="#主从复制" class="headerlink" title="主从复制"></a>主从复制</h2><p>主要涉及三个线程：binlog 线程、I/O 线程和 SQL 线程。</p><ul><li>binlog线程：负责将主服务器上的数据更改写入二进制日志（Binary log）中。</li><li>I/O线程：负责从主服务器上读取二进制日志，并写入从服务器的中继日志（Relay log）。</li><li>SQL线程：负责读取中继日志，解析出主服务器已经执行的数据更改并在从服务器中重放（Replay）。</li></ul><p><img src="http://img.hecenjie.cn/master-slave.png" alt></p><h2 id="读写分离"><a href="#读写分离" class="headerlink" title="读写分离"></a>读写分离</h2><p>主服务器处理写操作以及实时性要求比较高的读操作，而从服务器处理读操作。</p><p>读写分离能提高性能的原因在于</p><ul><li>主从服务器负责各自的读和写，极大程度缓解了锁的争用；</li><li>从服务器可以使用MyISAM，提升查询性能以及节约系统开销；</li><li>增加冗余，提高可用性。</li></ul><p><img src="http://img.hecenjie.cn/master-slave-proxy.png" alt></p><h2 id="分库分表"><a href="#分库分表" class="headerlink" title="分库分表"></a>分库分表</h2><p>当在主从复制、索引优化并且升级硬件后，数据库性能依然无法达到要求，此时就可以考虑数据库的切分，根据其切分类型，可以分为两种切分方式：垂直切分和水平切分。</p><h3 id="垂直切分"><a href="#垂直切分" class="headerlink" title="垂直切分"></a>垂直切分</h3><p>垂直切分又分为垂直分库和垂直分表。</p><p>垂直分库就是根据业务耦合性，将关联度低的不同表存储在不同的数据库。做法与大系统拆分为多个小系统类似，按业务分类进行独立划分。与”微服务治理”的做法相似，每个微服务使用单独的一个数据库。（例如用户User一个库，商品Producet一个库，订单Order一个库）</p><p>垂直分表是针对列进行的。如果某个表的字段较多，可以把不常用的字段或者长度较长的字段拆分到一张新的扩展表中。在字段较多的情况下，通过“大表拆小表”，更有利于维护与开发，也能避免跨页问题（一致性、排序等问题）。MySQL底层是通过数据页存储的，一条记录占用空间过大会导致跨页，造成额外的性能开销。另外数据库以行为单位将数据加载到内存中，这样表中字段长度较短且访问频率较高，内存能加载更多的数据，命中率更高，减少了磁盘IO，从而提升了数据库性能。</p><h3 id="水平切分"><a href="#水平切分" class="headerlink" title="水平切分"></a>水平切分</h3><p>因为垂直切分并没有解决单表数据量过大的问题（1000W行切分后还是1000W行），所以当还是无法满足需求的时候，可以进行水平切分。水平切分有以下几种方式：</p><ul><li>范围切分：比如按照时间区间或ID区间来切分，这可以使得冷热数据分离。由于是顺序存储，天然适合水平扩展，但是无法解决集中写入瓶颈的问题。</li><li>Hash切分：通过Hash取模解决了数据访问不均匀的问题，但是在集群扩容的时候，数据迁移量是很大的（使用一致性hash算法能较好的避免这个问题）。</li></ul><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://www.cnblogs.com/butterfly100/p/9034281.html" target="_blank" rel="noopener">数据库分库分表思路</a></li><li><a href="http://codingcms.cn/2019/05/14/MySQL_4/" target="_blank" rel="noopener">MySQL 分库分表策略</a></li><li><a href="https://cyc2018.github.io/CS-Notes/#/notes/MySQL?id=%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6" target="_blank" rel="noopener">CS-NOTE</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;主从复制&quot;&gt;&lt;a href=&quot;#主从复制&quot; class=&quot;headerlink&quot; title=&quot;主从复制&quot;&gt;&lt;/a&gt;主从复制&lt;/h2&gt;&lt;p&gt;主要涉及三个线程：binlog 线程、I/O 线程和 SQL 线程。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;binlog线程：负责将主服
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>GET和POST的区别</title>
    <link href="http://yoursite.com/2019/05/26/PUT%E5%92%8CPOST%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    <id>http://yoursite.com/2019/05/26/PUT和POST的区别/</id>
    <published>2019-05-26T11:13:46.000Z</published>
    <updated>2019-05-26T12:06:34.000Z</updated>
    
    <content type="html"><![CDATA[<ol start="0"><li>GET用于资源获取，是安全且幂等的，安全的意思是仅仅会获取资源而不会影响资源状态，幂等则是对同一URL的多次请求应该返回同样的结果；POST主要用来传输数据，多次调用会产生多个新的资源，因此是不安全且非幂等的。</li><li>GET请求的数据会包含在URL中，而POST请求则把数据放置在HTTP请求体中。</li><li>正因为GET请求是通过URL提交数据，所以GET请求可提交的数据量跟URL的长度有关系，而POST请求从理论上讲是没有大小限制，可传较大量的数据。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ol start=&quot;0&quot;&gt;
&lt;li&gt;GET用于资源获取，是安全且幂等的，安全的意思是仅仅会获取资源而不会影响资源状态，幂等则是对同一URL的多次请求应该返回同样的结果；POST主要用来传输数据，多次调用会产生多个新的资源，因此是不安全且非幂等的。&lt;/li&gt;
&lt;li&gt;GET请求的
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>TCP与UDP的区别</title>
    <link href="http://yoursite.com/2019/05/26/TCP%E4%B8%8EUDP%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    <id>http://yoursite.com/2019/05/26/TCP与UDP的区别/</id>
    <published>2019-05-26T11:11:00.000Z</published>
    <updated>2019-05-26T11:29:56.000Z</updated>
    
    <content type="html"><![CDATA[<p>OSI和TCP/IP模型在传输层定义了两种传输协议：TCP（传输控制协议）和 UDP（用户数据报协议）。它们的主要区别如下：</p><ol><li>面向连接与无连接</li><li>TCP保证数据可靠性，错误重发；UDP不可靠，可能丢包 </li><li>TCP保证数据顺序，UDP不保证</li><li>TCP主要提供完整性服务，UDP主要提供及时性服务</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;OSI和TCP/IP模型在传输层定义了两种传输协议：TCP（传输控制协议）和 UDP（用户数据报协议）。它们的主要区别如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;面向连接与无连接&lt;/li&gt;
&lt;li&gt;TCP保证数据可靠性，错误重发；UDP不可靠，可能丢包 &lt;/li&gt;
&lt;li&gt;TCP保证
      
    
    </summary>
    
      <category term="计算机网络" scheme="http://yoursite.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="计算机网络" scheme="http://yoursite.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
      <category term="TCP" scheme="http://yoursite.com/tags/TCP/"/>
    
  </entry>
  
  <entry>
    <title>@Autowired源码分析</title>
    <link href="http://yoursite.com/2019/05/24/Autowired%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
    <id>http://yoursite.com/2019/05/24/Autowired源码分析/</id>
    <published>2019-05-24T06:24:18.000Z</published>
    <updated>2019-05-24T06:24:56.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="AutowiredAnnotationBeanPostProcessor"><a href="#AutowiredAnnotationBeanPostProcessor" class="headerlink" title="AutowiredAnnotationBeanPostProcessor"></a>AutowiredAnnotationBeanPostProcessor</h2><p><code>@Autowired</code>注解的逻辑是由<code>AutowiredAnnotationBeanPostProcessor</code>实现的，<code>AutowiredAnnotationBeanPostProcessor</code>不是一个简单的<code>BeanPostProcessor</code>，而是一个实现了多重接口的<code>BeanPostProcessor</code>，它主要实现了以下两个接口：</p><ul><li><code>InstantiationAwareBeanPostProcessor</code>：对应<code>postProcessPropertyValues()</code>方法</li><li><code>MergedBeanDefinitionPostProcessor</code>：对应<code>findAutowiringMetadata</code>方法</li></ul><p>下面我们分别来看看这两个接口的实现是如何完成<code>@Autowired</code>的逻辑的。</p><h2 id="作为MergedBeanDefinitionPostProcessor的行为"><a href="#作为MergedBeanDefinitionPostProcessor的行为" class="headerlink" title="作为MergedBeanDefinitionPostProcessor的行为"></a>作为MergedBeanDefinitionPostProcessor的行为</h2><p>首先，我们从<code>ApplicationContext</code>体系最核心的<code>refresh()</code>方法说起：<br><img src="http://blog.default.nanwulife.com/162cc16e4b0eee57.jpg" alt></p><p><code>refresh()</code>方法中<code>registerBeanPostProcessors(beanFactory)</code>这一行代码完成了对<code>AutowiredAnnotationBeanPostProcessor</code>的注册，当执行<code>finishBeanFactoryInitialization(beanFactory)</code>方法时，会实例化所有非懒加载的单例Bean，这个过程中会调用<code>AbstractAutowireCapableBeanFactory</code>类的<code>doCreateBean()</code>方法，其中在使用合适的实例化策略实例化完Bean之后，会有下面这么一段代码：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> Object <span class="title">doCreateBean</span><span class="params">(<span class="keyword">final</span> String beanName, <span class="keyword">final</span> RootBeanDefinition mbd, <span class="keyword">final</span> Object[] args)</span></span></span><br><span class="line"><span class="function">            <span class="keyword">throws</span> BeanCreationException </span>&#123;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    <span class="keyword">synchronized</span> (mbd.postProcessingLock) &#123;</span><br><span class="line">        <span class="keyword">if</span> (!mbd.postProcessed) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                applyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName); <span class="comment">// 重点关注这一行</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">catch</span> (Throwable ex) &#123;</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> BeanCreationException(mbd.getResourceDescription(), beanName,</span><br><span class="line">                        <span class="string">"Post-processing of merged bean definition failed"</span>, ex);</span><br><span class="line">            &#125;</span><br><span class="line">            mbd.postProcessed = <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">applyMergedBeanDefinitionPostProcessors</span><span class="params">(RootBeanDefinition mbd, Class&lt;?&gt; beanType, String beanName)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (BeanPostProcessor bp : getBeanPostProcessors()) &#123;</span><br><span class="line">        <span class="keyword">if</span> (bp <span class="keyword">instanceof</span> MergedBeanDefinitionPostProcessor) &#123;</span><br><span class="line">            MergedBeanDefinitionPostProcessor bdp = (MergedBeanDefinitionPostProcessor) bp;</span><br><span class="line">            bdp.postProcessMergedBeanDefinition(mbd, beanType, beanName);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>在<code>applyMergedBeanDefinitionPostProcessors()</code>方法中，会判断当前的<code>BeanPostProcessor</code>是否是<code>MergedBeanDefinitionPostProcessor</code>类型的，如果是的话则调用它的<code>postProcessMergedBeanDefinition()</code>方法（显然，这里会判断为真，因为<code>AutowiredAnnotationBeanPostProcessor</code>实现了<code>MergedBeanDefinitionPostProcessor</code>）。我们再来看看<code>AutowiredAnnotationBeanPostProcessor</code>对该方法的实现：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">postProcessMergedBeanDefinition</span><span class="params">(RootBeanDefinition beanDefinition, Class&lt;?&gt; beanType, String beanName)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (beanType != <span class="keyword">null</span>) &#123;</span><br><span class="line">        InjectionMetadata metadata = findAutowiringMetadata(beanName, beanType, <span class="keyword">null</span>);</span><br><span class="line">        metadata.checkConfigMembers(beanDefinition);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> InjectionMetadata <span class="title">findAutowiringMetadata</span><span class="params">(String beanName, Class&lt;?&gt; clazz, PropertyValues pvs)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    String cacheKey = (StringUtils.hasLength(beanName) ? beanName : clazz.getName());</span><br><span class="line">    InjectionMetadata metadata = <span class="keyword">this</span>.injectionMetadataCache.get(cacheKey); <span class="comment">// 先从缓存中找 InjectionMetadata，诸如 @Autowire，@Inject 等</span></span><br><span class="line">    <span class="keyword">if</span> (InjectionMetadata.needsRefresh(metadata, clazz)) &#123;                  <span class="comment">// 如果找不到，则从这里开始，通过分析 bean，去找到它的 InjectionMetadata</span></span><br><span class="line">        <span class="keyword">synchronized</span> (<span class="keyword">this</span>.injectionMetadataCache) &#123;</span><br><span class="line">            metadata = <span class="keyword">this</span>.injectionMetadataCache.get(cacheKey);</span><br><span class="line">            <span class="keyword">if</span> (InjectionMetadata.needsRefresh(metadata, clazz)) &#123;</span><br><span class="line">                <span class="keyword">if</span> (metadata != <span class="keyword">null</span>) &#123;</span><br><span class="line">                    metadata.clear(pvs);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    metadata = buildAutowiringMetadata(clazz);              <span class="comment">// 重点关注：去找，并构建其 InjectionMetadata 对象</span></span><br><span class="line">                    <span class="keyword">this</span>.injectionMetadataCache.put(cacheKey, metadata);    <span class="comment">// 如果找到了，将其放入 injectionMetadataCache 中返回；</span></span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">catch</span> (NoClassDefFoundError err) &#123;</span><br><span class="line">                    <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">"Failed to introspect bean class ["</span> + clazz.getName() +</span><br><span class="line">                            <span class="string">"] for autowiring metadata: could not find class that it depends on"</span>, err);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> metadata;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><code>findAutowiringMetadata()</code>方法先从缓存中判断否已经存在该<code>InjectionMetadata</code>了，如果存在，且无需进行刷新，则返回；如果缓存中不存在（或者存在但需要刷新），那么就需要去构建一个<code>InjectionMetadata</code>。</p><p>接下来就是比较核心的部分了，通过<code>buildAutowiringMetadata()</code>方法构建<code>InjectionMetadata</code>对象：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> InjectionMetadata <span class="title">buildAutowiringMetadata</span><span class="params">(<span class="keyword">final</span> Class&lt;?&gt; clazz)</span> </span>&#123;</span><br><span class="line">    LinkedList&lt;InjectionMetadata.InjectedElement&gt; elements = <span class="keyword">new</span> LinkedList&lt;InjectionMetadata.InjectedElement&gt;();</span><br><span class="line">    Class&lt;?&gt; targetClass = clazz;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">do</span> &#123;</span><br><span class="line">        <span class="keyword">final</span> LinkedList&lt;InjectionMetadata.InjectedElement&gt; currElements =</span><br><span class="line">                <span class="keyword">new</span> LinkedList&lt;InjectionMetadata.InjectedElement&gt;();</span><br><span class="line">        <span class="comment">// 1. 通过反射从 targetClass 的 field 中去找注解</span></span><br><span class="line">        ReflectionUtils.doWithLocalFields(targetClass, <span class="keyword">new</span> ReflectionUtils.FieldCallback() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doWith</span><span class="params">(Field field)</span> <span class="keyword">throws</span> IllegalArgumentException, IllegalAccessException </span>&#123;</span><br><span class="line">                AnnotationAttributes ann = findAutowiredAnnotation(field); <span class="comment">// 是否存在 @Autowired</span></span><br><span class="line">                <span class="keyword">if</span> (ann != <span class="keyword">null</span>) &#123;</span><br><span class="line">                    <span class="keyword">if</span> (Modifier.isStatic(field.getModifiers())) &#123;</span><br><span class="line">                        <span class="keyword">if</span> (logger.isWarnEnabled()) &#123;</span><br><span class="line">                            logger.warn(<span class="string">"Autowired annotation is not supported on static fields: "</span> + field);</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">return</span>; <span class="comment">// 如果当前处理的属性是静态属性，则直接返回</span></span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="keyword">boolean</span> required = determineRequiredStatus(ann);</span><br><span class="line">                    currElements.add(<span class="keyword">new</span> AutowiredFieldElement(field, required));</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="comment">// 2. 通过反射从 targetClass 的 method 中去找注解</span></span><br><span class="line">        ReflectionUtils.doWithLocalMethods(targetClass, <span class="keyword">new</span> ReflectionUtils.MethodCallback() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doWith</span><span class="params">(Method method)</span> <span class="keyword">throws</span> IllegalArgumentException, IllegalAccessException </span>&#123;</span><br><span class="line">                Method bridgedMethod = BridgeMethodResolver.findBridgedMethod(method);</span><br><span class="line">                <span class="keyword">if</span> (!BridgeMethodResolver.isVisibilityBridgeMethodPair(method, bridgedMethod)) &#123;</span><br><span class="line">                    <span class="keyword">return</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// 上述代码处理 bridged method 相关情况；可忽略；</span></span><br><span class="line">                AnnotationAttributes ann = findAutowiredAnnotation(bridgedMethod); <span class="comment">// 是否存在 @Autowired</span></span><br><span class="line">                <span class="keyword">if</span> (ann != <span class="keyword">null</span> &amp;&amp; method.equals(ClassUtils.getMostSpecificMethod(method, clazz))) &#123;</span><br><span class="line">                    <span class="keyword">if</span> (Modifier.isStatic(method.getModifiers())) &#123;</span><br><span class="line">                        <span class="keyword">if</span> (logger.isWarnEnabled()) &#123;</span><br><span class="line">                            logger.warn(<span class="string">"Autowired annotation is not supported on static methods: "</span> + method);</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">return</span>; <span class="comment">// 如果方法是静态的，则直接返回；</span></span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="keyword">if</span> (method.getParameterTypes().length == <span class="number">0</span>) &#123;</span><br><span class="line">                        <span class="keyword">if</span> (logger.isWarnEnabled()) &#123;</span><br><span class="line">                            logger.warn(<span class="string">"Autowired annotation should only be used on methods with parameters: "</span> +</span><br><span class="line">                                    method); <span class="comment">// 警告，方法参数长度为 0</span></span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="keyword">boolean</span> required = determineRequiredStatus(ann);</span><br><span class="line">                    PropertyDescriptor pd = BeanUtils.findPropertyForMethod(bridgedMethod, clazz);</span><br><span class="line">                    currElements.add(<span class="keyword">new</span> AutowiredMethodElement(method, required, pd));</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        elements.addAll(<span class="number">0</span>, currElements);</span><br><span class="line">        targetClass = targetClass.getSuperclass();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">while</span> (targetClass != <span class="keyword">null</span> &amp;&amp; targetClass != Object<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> InjectionMetadata(clazz, elements);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>该方法分为两部分，通过工具类<code>ReflectionUtils</code>分别从当前Bean实例的<code>fields</code>和<code>methods</code>中去查找<code>@Autowired</code>注解：</p><ol><li>从<code>fields</code>找<code>@Autowired</code>注解，若找到，则创建<code>AutowiredFieldElement</code>实例，并放入<code>currElements</code>队列中</li><li>从<code>methods</code>中找<code>@Autowired</code>注解，若找到，则创建<code>AutowiredMethodElement</code>实例，并放入<code>currElements</code>队列中</li><li>最后，通过Bean的Class对象和<code>curreElements</code>构建<code>InjectionMetadata</code>实例并返回</li></ol><p>此时，将构建好的<code>InjectionMetadata</code>加入缓存<code>injectionMetadataCache</code>中并返回。</p><h2 id="作为InstantiationAwareBeanPostProcessor的行为"><a href="#作为InstantiationAwareBeanPostProcessor的行为" class="headerlink" title="作为InstantiationAwareBeanPostProcessor的行为"></a>作为InstantiationAwareBeanPostProcessor的行为</h2><p>同样，在<code>doCreateBean()</code>方法中执行<code>populateBean()</code>方法填充属性时，<code>populateBean()</code>方法中有如下一段代码：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (hasInstAwareBpps || needsDepCheck) &#123;</span><br><span class="line"><span class="keyword">if</span> (pvs == <span class="keyword">null</span>) &#123;</span><br><span class="line">pvs = mbd.getPropertyValues();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PropertyDescriptor[] filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching);</span><br><span class="line"><span class="keyword">if</span> (hasInstAwareBpps) &#123;</span><br><span class="line"><span class="keyword">for</span> (BeanPostProcessor bp : getBeanPostProcessors()) &#123;</span><br><span class="line"><span class="keyword">if</span> (bp <span class="keyword">instanceof</span> InstantiationAwareBeanPostProcessor) &#123;</span><br><span class="line">InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp;</span><br><span class="line">pvs = ibp.postProcessPropertyValues(pvs, filteredPds, bw.getWrappedInstance(), beanName);<span class="comment">// 重点关注这一行</span></span><br><span class="line"><span class="keyword">if</span> (pvs == <span class="keyword">null</span>) &#123;</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>其中，<code>pvs = ibp.postProcessPropertyValues()</code>这行代码调用了<code>InstantiationAwareBeanPostProcessor</code>的接口方法，继续跟进去看。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> PropertyValues <span class="title">postProcessPropertyValues</span><span class="params">(PropertyValues pvs, PropertyDescriptor[] pds, Object bean, String beanName)</span> <span class="keyword">throws</span> BeanCreationException </span>&#123;</span><br><span class="line"><span class="comment">// &lt;1&gt;</span></span><br><span class="line">InjectionMetadata metadata = findAutowiringMetadata(beanName, bean.getClass(), pvs);</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">       <span class="comment">// &lt;2&gt;</span></span><br><span class="line">metadata.inject(bean, beanName, pvs);</span><br><span class="line">&#125; <span class="keyword">catch</span> (BeanCreationException ex) &#123;</span><br><span class="line"><span class="keyword">throw</span> ex;</span><br><span class="line">&#125; <span class="keyword">catch</span> (Throwable ex) &#123;</span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> pvs;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在刚实例化完Bean之后，作为<code>MergedBeanDefinitionPostProcessor</code>，已经调用过<code>findAutowiringMetadata()</code>方法，即从当前Bean对象中的属性和方法中找到了<code>@Autowired</code>注解，并将它们封装成了<code>InjectionMetadata</code>放入了缓存当中，因此，此处直接从缓存中就可以获取到该Bean对应的<code>InjectMetadata</code>。接下来就是通过<code>InjectMetadata</code>进行注入：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">inject</span><span class="params">(Object target, @Nullable String beanName, @Nullable PropertyValues pvs)</span> <span class="keyword">throws</span> Throwable </span>&#123;</span><br><span class="line">Collection&lt;InjectedElement&gt; checkedElements = <span class="keyword">this</span>.checkedElements;</span><br><span class="line">Collection&lt;InjectedElement&gt; elementsToIterate =</span><br><span class="line">(checkedElements != <span class="keyword">null</span> ? checkedElements : <span class="keyword">this</span>.injectedElements);</span><br><span class="line"><span class="keyword">if</span> (!elementsToIterate.isEmpty()) &#123;</span><br><span class="line"><span class="keyword">for</span> (InjectedElement element : elementsToIterate) &#123;</span><br><span class="line"><span class="keyword">if</span> (logger.isDebugEnabled()) &#123;</span><br><span class="line">logger.debug(<span class="string">"Processing injected element of bean '"</span> + beanName + <span class="string">"': "</span> + element);</span><br><span class="line">&#125;</span><br><span class="line">element.inject(target, beanName, pvs);<span class="comment">// 重点关注</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">   </span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">inject</span><span class="params">(Object target, @Nullable String requestingBeanName, @Nullable PropertyValues pvs)</span></span></span><br><span class="line"><span class="function"><span class="keyword">throws</span> Throwable </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (<span class="keyword">this</span>.isField) &#123;</span><br><span class="line">Field field = (Field) <span class="keyword">this</span>.member;</span><br><span class="line">ReflectionUtils.makeAccessible(field);</span><br><span class="line">field.set(target, getResourceToInject(target, requestingBeanName));<span class="comment">// 重点关注</span></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="keyword">if</span> (checkPropertySkipping(pvs)) &#123;</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">Method method = (Method) <span class="keyword">this</span>.member;</span><br><span class="line">ReflectionUtils.makeAccessible(method);</span><br><span class="line">method.invoke(target, getResourceToInject(target, requestingBeanName));<span class="comment">// 重点关注</span></span><br><span class="line">&#125; <span class="keyword">catch</span> (InvocationTargetException ex) &#123;</span><br><span class="line"><span class="keyword">throw</span> ex.getTargetException();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>由于<code>InjectionMetadata</code>对象本身包含了一系列的<code>AutowiredFieldElement</code>和<code>AutowiredMethodElement</code>，所以这里迭代<code>InjectedElement</code>并依次处理它们，而处理的逻辑都在<code>inject()</code>这一关键方法中，可以看到最终就是根据是属性还是方法来分别使用反射注入，并且对于方法而言，该方法会被调用。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://www.shangyang.me/2017/04/05/spring-core-container-sourcecode-analysis-annotation-autowired/" target="_blank" rel="noopener">Spring Core Container 源码分析五：@Autowired</a></li><li><a href="https://juejin.im/entry/5ad3fda5f265da238d512a98" target="_blank" rel="noopener">深入理解Spring系列之十四：@Autowired是如何工作的</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;AutowiredAnnotationBeanPostProcessor&quot;&gt;&lt;a href=&quot;#AutowiredAnnotationBeanPostProcessor&quot; class=&quot;headerlink&quot; title=&quot;AutowiredAnnotationB
      
    
    </summary>
    
    
  </entry>
  
</feed>
